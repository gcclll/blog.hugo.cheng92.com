<!DOCTYPE html>
<html lang="en">
<head>
  <!-- 2022-03-12 Sat 20:18 -->
  <meta charset="utf-8">
  <meta name="viewport" content=
  "width=device-width, initial-scale=1">
  <title>Documentations</title>
  <meta name="author" content="Zhicheng Lee">
  <meta name="generator" content="Org Mode">
  <style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  </style>
  <link rel="stylesheet" type="text/css" href=
  "/assets/css/htmlize.css">
  <link rel="stylesheet" type="text/css" href=
  "/assets/css/readtheorg.css">
  <link rel="stylesheet" type="text/css" href=
  "/assets/css/global.css">
  <link rel="stylesheet" type="text/css" href=
  "/assets/css/element-plus.css">
  <script type="text/javascript" src=
  "/assets/js/jquery.min.js"></script>
  <script type="text/javascript" src=
  "/assets/js/jquery.stickytableheaders.min.js"></script>
  <script type="text/javascript" src=
  "/assets/js/bootstrap.min.js"></script>
  <script type="text/javascript" src=
  "/assets/js/lodash.min.js"></script>
  <script type="text/javascript" src=
  "/assets/js/mobile-detect.min.js"></script>
  <script type="text/javascript" src=
  "/assets/js/Valine.min.js"></script>
  <script type="text/javascript" src="/assets/js/vue.js"></script>
  <script type="text/javascript" src=
  "/assets/js/element-plus.js"></script>
  <script type="text/javascript" src=
  "/assets/js/readtheorg.js"></script>
  <script type="text/javascript" src=
  "/assets/js/dist/stats.js"></script>
  <script type="text/javascript" src=
  "/assets/js/dist/global.js"></script>
  <meta name="category" content="emacs">
  <meta name="tags" content="org-mode">
  <style>
        /* From: https://endlessparentheses.com/public/css/endless.css */
        /* See also: https://meta.superuser.com/questions/4788/css-for-the-new-kbd-style */
        kbd
        {
          -moz-border-radius: 6px;
          -moz-box-shadow: 0 1px 0 rgba(0,0,0,0.2),0 0 0 2px #fff inset;
          -webkit-border-radius: 6px;
          -webkit-box-shadow: 0 1px 0 rgba(0,0,0,0.2),0 0 0 2px #fff inset;
          background-color: #f7f7f7;
          border: 1px solid #ccc;
          border-radius: 6px;
          box-shadow: 0 1px 0 rgba(0,0,0,0.2),0 0 0 2px #fff inset;
          color: #333;
          display: inline-block;
          font-family: 'Droid Sans Mono', monospace;
          font-size: 80%;
          font-weight: normal;
          line-height: inherit;
          margin: 0 .1em;
          padding: .08em .4em;
          text-shadow: 0 1px 0 #fff;
          word-spacing: -4px;
        
          box-shadow: 2px 2px 2px #222; /* MA: An extra I've added. */
        }
  </style>
  <link rel="stylesheet" type="text/css" href=
  "/assets/css/tooltipster.bundle.min.css">
  <link rel="stylesheet" type="text/css" href=
  "/assets/css/tooltipster-sideTip-punk.min.css">
  <script type="text/javascript">
            if (typeof jQuery == 'undefined') {
                document.write(unescape('%3Cscript src="https://code.jquery.com/jquery-1.10.0.min.js"%3E%3C/script%3E'));
            }
  </script>
  <script type="text/javascript" src=
  "/assets/js/tooltipster.bundle.min.js"></script>
  <script type="text/javascript" src=
  "/assets/js/tooltipster-scrollableTip.min.js"></script>
  <script type="text/javascript" src=
  "/assets/js/dist/tooltips.js"></script>
  <style>
           abbr {color: red;}
        
           .tooltip { border-bottom: 1px dotted #000;
                      color:red;
                      text-decoration: none;}
  </style>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
  });
  </script>
  <script src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
  <div id="content" class="content">
    <h1 class="title">Documentations</h1>
    <div id="table-of-contents" role="doc-toc">
      <h2>Table of Contents</h2>
      <div id="text-table-of-contents" role="doc-toc">
        <ul>
          <li>
            <a href="#Logics">1. Logics & Programming
            Abstractions</a>
            <ul>
              <li>
                <a href="#Misc">1.1.
                Misc&nbsp;&nbsp;&nbsp;<span class=
                "tag"><span class="ignore">ignore</span></span></a>
              </li>
            </ul>
          </li>
          <li>
            <a href="#Properties-of-Operators-Relations">2.
            Properties of Operators</a>
          </li>
          <li>
            <a href="#Properties-of-Homogeneous-Relations">3.
            Properties of <i>Homogeneous</i> Relations</a>
          </li>
          <li>
            <a href="#Properties-of-Heterogeneous-Relations">4.
            Properties of <i>Heterogeneous</i> Relations</a>
          </li>
          <li>
            <a href="#orgc9bf56a">5. Programming Development
            Relations</a>
          </li>
        </ul>
      </div>
    </div>
    <p><a href="/"><img src=
    "https://img.shields.io/badge/GCCLL-Homepage-green?logo=gnu-emacs"></a></p>
    <blockquote>
      <p><i>Knowledge is software for your brain: The more you
      know, the more problems you can solve!</i></p>
    </blockquote>
    <p><a href="http://r6.ca/blog/20171008T222703Z.html">Taking
    Propositions as Types Seriously</a> a nice brief read by
    Russell O’Connor, to link to.</p>
    <p>Foundations of Algebraic Specification and Formal Software
    Development Authors: Donald Sannella, Andrzej Tarlecki <a href=
    "http://link.springer.com/book/10.1007%2F978-3-642-17336-3">http://link.springer.com/book/10.1007%2F978-3-642-17336-3</a></p>
    <p>(You can access this via the McMaster library using you
    MacID login: <a href=
    "http://catalogue.mcmaster.ca/catalogue/Record/1950176">http://catalogue.mcmaster.ca/catalogue/Record/1950176</a>
    )</p>
    <p></p>
    <p><abbr class="tooltip" title="">temp</abbr></p>
    <div style=
    "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
      <h3>temp</h3>
    </div>
    <p><abbr class="tooltip" title=
    "Hussein ibn Ali is the grandson of Prophet Muhammad, who is known to have&lt;br&gt;declared &lt;strong&gt;“Hussain is from me and I am from Hussain; God loves whoever loves Hussain.”&lt;/strong&gt;&lt;br&gt;&lt;br&gt;He is honoured as “The Chief of Martyrs” for his selfless stand for social justice&lt;br&gt;against Yazid, the corrupt 7ᵗʰ caliph. The Karbala Massacre is commemorated annually&lt;br&gt;in the first Islamic month, Muharram, as a reminder to stand against oppression and tyranny;&lt;br&gt;Jesus Christ, son of Mary, makes an indirect appearance in the story.&lt;br&gt;&lt;br&gt;A terse summary of the chain of events leading to the massacre may be found at&lt;br&gt;https://www.al-islam.org/articles/karbala-chain-events.&lt;br&gt;&lt;br&gt;An elegant English recitation recounting the Karbala Massacre may be found at&lt;br&gt;https://youtu.be/2i9Y3Km6h08 ---“Arbaeen Maqtal - Sheikh Hamam Nassereddine - 1439”.&lt;br&gt;&lt;hr&gt;&lt;br&gt; &lt;strong&gt;Charles Dickens:&lt;/strong&gt; &lt;em&gt;“If Hussain had fought to quench his worldly desires...then I&lt;/em&gt;&lt;br&gt;&lt;em&gt;do not understand why his sister, wife, and children accompanied him. It stands&lt;br&gt;to reason therefore, that he sacrificed purely for Islam.”&lt;/em&gt;&lt;br&gt;&lt;br&gt;&lt;strong&gt;Gandhi:&lt;/strong&gt; &lt;em&gt;“I learned from Hussain how to achieve victory while being oppressed.”&lt;/em&gt;&lt;br&gt;&lt;br&gt;&lt;strong&gt;Thomas Carlyle:&lt;/strong&gt; &lt;em&gt;“The victory of Hussein, despite his minority, marvels me.”&lt;/em&gt;&lt;br&gt;&lt;br&gt;&lt;strong&gt;Thomas Masaryk:&lt;/strong&gt; &lt;em&gt;“Although our clergies also move us while describing the&lt;br&gt;Christ's sufferings, but the zeal and zest that is found in the followers of&lt;/em&gt;&lt;br&gt;&lt;em&gt;Hussain will not be found in the followers of Christ. And it seems that the&lt;br&gt;suffering of Christ against the suffering of Hussain is like a blade of straw&lt;/em&gt; &lt;em&gt;in&lt;br&gt;front of a huge mountain.”&lt;/em&gt;">
    Hussain</abbr></p>
    <div style=
    "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
      <h3>Hussain</h3>
      <p>Hussein ibn Ali is the grandson of Prophet Muhammad, who
      is known to have declared <b>“Hussain is from me and I am
      from Hussain; God loves whoever loves Hussain.”</b></p>
      <p>He is honoured as “The Chief of Martyrs” for his selfless
      stand for social justice against Yazid, the corrupt 7ᵗʰ
      caliph. The Karbala Massacre is commemorated annually in the
      first Islamic month, Muharram, as a reminder to stand against
      oppression and tyranny; Jesus Christ, son of Mary, makes an
      indirect appearance in the story.</p>
      <p>A terse summary of the chain of events leading to the
      massacre may be found at <a href=
      "https://www.al-islam.org/articles/karbala-chain-events">https://www.al-islam.org/articles/karbala-chain-events</a>.</p>
      <p>An elegant English recitation recounting the Karbala
      Massacre may be found at <a href=
      "https://youtu.be/2i9Y3Km6h08">https://youtu.be/2i9Y3Km6h08</a>
      —“Arbaeen Maqtal - Sheikh Hamam Nassereddine - 1439”.</p>
      <hr>
      <p><b>Charles Dickens:</b> <i>“If Hussain had fought to
      quench his worldly desires…then I</i> <i>do not understand
      why his sister, wife, and children accompanied him. It stands
      to reason therefore, that he sacrificed purely for
      Islam.”</i></p>
      <p><b>Gandhi:</b> <i>“I learned from Hussain how to achieve
      victory while being oppressed.”</i></p>
      <p><b>Thomas Carlyle:</b> <i>“The victory of Hussein, despite
      his minority, marvels me.”</i></p>
      <p><b>Thomas Masaryk:</b> <i>“Although our clergies also move
      us while describing the Christ’s sufferings, but the zeal and
      zest that is found in the followers of</i> <i>Hussain will
      not be found in the followers of Christ. And it seems that
      the suffering of Christ against the suffering of Hussain is
      like a blade of straw</i> <i>in front of a huge
      mountain.”</i></p>
    </div>
    <p><abbr class="tooltip" title=
    "Language (Native Name) “Hello”&lt;br&gt;1. Amharic (አማርኛ) ሠላም&lt;br&gt;2. Arabic (العربيّة) السّلام عليكم&lt;br&gt;3. Armenian (հայերեն) Բարև ձեզ&lt;br&gt;4. Bengali (বাংলা) নমস্কার&lt;br&gt;5. Braille ⠓⠑⠇⠇⠕&lt;br&gt;6. Burmese (မြန်မာ) မင်္ဂလာပါ&lt;br&gt;7. C printf (''Hello, world!\n'');&lt;br&gt;8. Cherokee (ᏣᎳᎩ ᎦᏬᏂᎯᏍᏗ) ᎣᏏᏲ ╱ ᏏᏲ&lt;br&gt;9. Comanche ╱kəˈmæntʃiː╱ Haa marʉ́awe&lt;br&gt;10. Cree (ᓀᐦᐃᔭᐍᐏᐣ) ᑕᓂᓯ ╱ ᐙᒋᔮ&lt;br&gt;11. Czech (čeština) Dobrý den&lt;br&gt;12. Danish (dansk) Hej ╱ Goddag ╱ Halløj&lt;br&gt;13. Dutch (Nederlands) Hallo ╱ Dag&lt;br&gt;14. Efik ╱ˈɛfɪk╱ Mɔkɔm&lt;br&gt;15. Emacs emacs --no-splash -f view-hello-file&lt;br&gt;16. Emoji 👋&lt;br&gt;17. English ╱ˈɪŋɡlɪʃ╱ Hello&lt;br&gt;18. Esperanto Saluton (Eĥoŝanĝo ĉiuĵaŭde)&lt;br&gt;19. Estonian (eesti keel) Tere päevast ╱ Tere õhtust&lt;br&gt;20. Finnish (suomi) Hei ╱ Hyvää päivää&lt;br&gt;21. French (français) Bonjour ╱ Salut&lt;br&gt;22. Georgian (ქართული) გამარჯობა&lt;br&gt;23. German (Deutsch) Guten Tag ╱ Grüß Gott&lt;br&gt;24. Greek (ελληνικά) Γειά σας&lt;br&gt;25. Greek, ancient (ἑλληνική) Οὖλέ τε καὶ μέγα χαῖρε&lt;br&gt;26. Gujarati (ગુજરાતી) નમસ્તે&lt;br&gt;27. Hebrew (עִבְרִית) שָׁלוֹם&lt;br&gt;28. Hungarian (magyar) Szép jó napot!&lt;br&gt;29. Hindi (हिंदी) नमस्ते ╱ नमस्कार ।&lt;br&gt;30. Inuktitut (ᐃᓄᒃᑎᑐᑦ) ᐊᐃ&lt;br&gt;31. Italian (italiano) Ciao ╱ Buon giorno&lt;br&gt;32. Javanese (Jawa) System.out.println(''Sugeng siang!'');&lt;br&gt;33. Kannada (ಕನ್ನಡ) ನಮಸ್ಕಾರ&lt;br&gt;34. Khmer (ភាសាខ្មែរ) ជំរាបសួរ&lt;br&gt;35. Lao (ພາສາລາວ) ສະບາຍດີ ╱ ຂໍໃຫ້ໂຊກດີ&lt;br&gt;36. Malayalam (മലയാളം) നമസ്കാരം&lt;br&gt;37. Maldivian (ދިވެހި) އައްސަލާމު ޢަލައިކުމް ╱ ކިހިނެހް؟&lt;br&gt;38. Maltese (il-Malti) Bonġu ╱ Saħħa&lt;br&gt;39. Mathematics ∀ p ∈ world • hello p □&lt;br&gt;40. Mongolian (монгол хэл) Сайн байна уу?&lt;br&gt;41. Norwegian (norsk) Hei ╱ God dag&lt;br&gt;42. Oriya (ଓଡ଼ିଆ) ଶୁଣିବେ&lt;br&gt;43. Polish (język polski) Dzień dobry! ╱ Cześć!&lt;br&gt;44. Russian (русский) Здра́вствуйте!&lt;br&gt;45. Sinhala (සිංහල) ආයුබෝවන්&lt;br&gt;46. Slovak (slovenčina) Dobrý deň&lt;br&gt;47. Slovenian (slovenščina) Pozdravljeni!&lt;br&gt;48. Spanish (español) ¡Hola!&lt;br&gt;49. Swedish (svenska) Hej ╱ Goddag ╱ Hallå&lt;br&gt;50. Tamil (தமிழ்) வணக்கம்&lt;br&gt;51. Telugu (తెలుగు) నమస్కారం&lt;br&gt;52. TaiViet (ꪁꪫꪱꪣ ꪼꪕ) ꪅꪰꪙꫂ ꪨꪮꫂ ꪁꪫꪱ ╱ ꪅꪽ ꪨꪷ ꪁꪫꪱ&lt;br&gt;53. Thai (ภาษาไทย) สวัสดีครับ ╱ สวัสดีค่ะ&lt;br&gt;54. Tibetan (བོད་སྐད་) བཀྲ་ཤིས་བདེ་ལེགས༎&lt;br&gt;55. Tigrigna (ትግርኛ) ሰላማት&lt;br&gt;56. Turkish (Türkçe) Merhaba&lt;br&gt;57. Ukrainian (українська) Вітаю&lt;br&gt;58. Vietnamese (tiếng Việt) Chào bạn&lt;br&gt;59. Japanese (日本語) こんにちは ╱ ｺﾝﾆﾁﾊ&lt;br&gt;60. Chinese (中文,普通话,汉语) 你好&lt;br&gt;61. Cantonese (粵語,廣東話) 早晨, 你好&lt;br&gt;62. Korean (한글) 안녕하세요 ╱ 안녕하십니까&lt;br&gt;&lt;hr&gt;&lt;br&gt;This list was generated by pressing &lt;code&gt;C-h h&lt;/code&gt; in Emacs, &lt;code&gt;view-hello-file&lt;/code&gt;.">
    Hello</abbr></p>
    <div style=
    "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
      <h3>Hello</h3>
      <p>Language (Native Name) “Hello”</p>
      <ol class="org-ol">
        <li>Amharic (አማርኛ) ሠላም</li>
        <li>Arabic (العربيّة) السّلام عليكم</li>
        <li>Armenian (հայերեն) Բարև ձեզ</li>
        <li>Bengali (বাংলা) নমস্কার</li>
        <li>Braille ⠓⠑⠇⠇⠕</li>
        <li>Burmese (မြန်မာ) မင်္ဂလာပါ</li>
        <li>C printf (“Hello, world!\n”);</li>
        <li>Cherokee (ᏣᎳᎩ ᎦᏬᏂᎯᏍᏗ) ᎣᏏᏲ ╱ ᏏᏲ</li>
        <li>Comanche ╱kəˈmæntʃiː╱ Haa marʉ́awe</li>
        <li>Cree (ᓀᐦᐃᔭᐍᐏᐣ) ᑕᓂᓯ ╱ ᐙᒋᔮ</li>
        <li>Czech (čeština) Dobrý den</li>
        <li>Danish (dansk) Hej ╱ Goddag ╱ Halløj</li>
        <li>Dutch (Nederlands) Hallo ╱ Dag</li>
        <li>Efik ╱ˈɛfɪk╱ Mɔkɔm</li>
        <li>Emacs emacs –no-splash -f view-hello-file</li>
        <li>Emoji 👋</li>
        <li>English ╱ˈɪŋɡlɪʃ╱ Hello</li>
        <li>Esperanto Saluton (Eĥoŝanĝo ĉiuĵaŭde)</li>
        <li>Estonian (eesti keel) Tere päevast ╱ Tere õhtust</li>
        <li>Finnish (suomi) Hei ╱ Hyvää päivää</li>
        <li>French (français) Bonjour ╱ Salut</li>
        <li>Georgian (ქართული) გამარჯობა</li>
        <li>German (Deutsch) Guten Tag ╱ Grüß Gott</li>
        <li>Greek (ελληνικά) Γειά σας</li>
        <li>Greek, ancient (ἑλληνική) Οὖλέ τε καὶ μέγα χαῖρε</li>
        <li>Gujarati (ગુજરાતી) નમસ્તે</li>
        <li>Hebrew (עִבְרִית) שָׁלוֹם</li>
        <li>Hungarian (magyar) Szép jó napot!</li>
        <li>Hindi (हिंदी) नमस्ते ╱ नमस्कार ।</li>
        <li>Inuktitut (ᐃᓄᒃᑎᑐᑦ) ᐊᐃ</li>
        <li>Italian (italiano) Ciao ╱ Buon giorno</li>
        <li>Javanese (Jawa) System.out.println(“Sugeng
        siang!”);</li>
        <li>Kannada (ಕನ್ನಡ) ನಮಸ್ಕಾರ</li>
        <li>Khmer (ភាសាខ្មែរ) ជំរាបសួរ</li>
        <li>Lao (ພາສາລາວ) ສະບາຍດີ ╱ ຂໍໃຫ້ໂຊກດີ</li>
        <li>Malayalam (മലയാളം) നമസ്കാരം</li>
        <li>Maldivian (ދިވެހި) އައްސަލާމު ޢަލައިކުމް ╱
        ކިހިނެހް؟</li>
        <li>Maltese (il-Malti) Bonġu ╱ Saħħa</li>
        <li>Mathematics ∀ p ∈ world • hello p □</li>
        <li>Mongolian (монгол хэл) Сайн байна уу?</li>
        <li>Norwegian (norsk) Hei ╱ God dag</li>
        <li>Oriya (ଓଡ଼ିଆ) ଶୁଣିବେ</li>
        <li>Polish (język polski) Dzień dobry! ╱ Cześć!</li>
        <li>Russian (русский) Здра́вствуйте!</li>
        <li>Sinhala (සිංහල) ආයුබෝවන්</li>
        <li>Slovak (slovenčina) Dobrý deň</li>
        <li>Slovenian (slovenščina) Pozdravljeni!</li>
        <li>Spanish (español) ¡Hola!</li>
        <li>Swedish (svenska) Hej ╱ Goddag ╱ Hallå</li>
        <li>Tamil (தமிழ்) வணக்கம்</li>
        <li>Telugu (తెలుగు) నమస్కారం</li>
        <li>TaiViet (ꪁꪫꪱꪣ ꪼꪕ) ꪅꪰꪙꫂ ꪨꪮꫂ ꪁꪫꪱ ╱ ꪅꪽ ꪨꪷ ꪁꪫꪱ</li>
        <li>Thai (ภาษาไทย) สวัสดีครับ ╱ สวัสดีค่ะ</li>
        <li>Tibetan (བོད་སྐད་) བཀྲ་ཤིས་བདེ་ལེགས༎</li>
        <li>Tigrigna (ትግርኛ) ሰላማት</li>
        <li>Turkish (Türkçe) Merhaba</li>
        <li>Ukrainian (українська) Вітаю</li>
        <li>Vietnamese (tiếng Việt) Chào bạn</li>
        <li>Japanese (日本語) こんにちは ╱ ｺﾝﾆﾁﾊ</li>
        <li>Chinese (中文,普通话,汉语) 你好</li>
        <li>Cantonese (粵語,廣東話) 早晨, 你好</li>
        <li>Korean (한글) 안녕하세요 ╱ 안녕하십니까</li>
      </ol>
      <hr>
      <p>This list was generated by pressing <code>C-h h</code> in
      Emacs, <code>view-hello-file</code>.</p>
    </div>
    <div id="outline-container-Logics" class="outline-2">
      <h2 id="Logics"><span class="section-number-2">1.</span>
      Logics & Programming Abstractions</h2>
      <div class="outline-text-2" id="text-Logics">
        <p><abbr class="tooltip" title=
        "A &lt;em&gt;(Partial, resp. Total) Graph&lt;/em&gt; &lt;em&gt;G = (V, E, src, tgt)&lt;/em&gt; consists of&lt;br&gt;  + &lt;EM&gt;V&lt;/EM&gt;, a set of “points, nodes, vertices”&lt;br&gt;  + &lt;EM&gt;E&lt;/EM&gt;, a set of “arcs, edges”&lt;br&gt;  + &lt;em&gt;src, tgt : E ↔ V&lt;/em&gt;, a pair of &lt;em&gt;partial (resp. total)&lt;/em&gt; functions.&lt;br&gt;&lt;br&gt;⟦ Tersely put, in any category, a &lt;em&gt;graph&lt;/em&gt; is a parallel pair of morphisms. ⟧&lt;br&gt;&lt;br&gt;&lt;em&gt;Edge parallelism&lt;/em&gt; is the relation &lt;em&gt;Ξ = src ⨾ src ˘ ∩ tgt ⨾ tgt˘&lt;/em&gt;; two arcs are&lt;br&gt;related when they have the same starting point and the same ending point, which&lt;br&gt;both exist. Joyously, the name ‘Ξ’ is a neat reminder of the concept:&lt;br&gt;The name is three parallel lines, for the concept of edge(line) parallelism.&lt;br&gt;&lt;br&gt;+ A graph is &lt;em&gt;total&lt;/em&gt; exactly when &lt;em&gt;Id ⊆ Ξ&lt;/em&gt;; and so Ξ is an equivalence.&lt;br&gt;+ A graph has &lt;em&gt;no parallel arrows&lt;/em&gt; exactly when &lt;em&gt;Ξ ⊆ Id&lt;/em&gt;.&lt;br&gt;+ A graph is &lt;em&gt;simple&lt;/em&gt; exactly when &lt;em&gt;Ξ = Id&lt;/em&gt;.&lt;br&gt;&lt;br&gt;The &lt;em&gt;associated relation&lt;/em&gt; is the relation &lt;em&gt;_⟶_ = src ˘ ⨾ tgt&lt;/em&gt; that relates two nodes&lt;br&gt;when the first is the source of some edge that happens to have the second point&lt;br&gt;as its target. One uses the associated relation to study properties not&lt;br&gt;involving partial or parallel arrows. One writes &lt;em&gt;⟵&lt;/em&gt; for &lt;em&gt;⟶˘&lt;/em&gt;;&lt;br&gt;one writes ⟶⋆ for the &lt;em&gt;reachability&lt;/em&gt; relation.&lt;br&gt;&lt;br&gt;+ Node &lt;em&gt;y&lt;/em&gt; is &lt;em&gt;reachable via a non-empty path&lt;/em&gt; from node &lt;em&gt;x&lt;/em&gt; exactly when &lt;em&gt;x ⟶⁺ y&lt;/em&gt;.&lt;br&gt; - Node &lt;em&gt;x&lt;/em&gt; lies on a cycle exactly when &lt;em&gt;x ⟶⁺ x&lt;/em&gt;.&lt;br&gt; - A graph is &lt;em&gt;DAG, acylic, circuit-free,&lt;/em&gt; exactly when &lt;em&gt;⟶⁺ ⊆ ∼Id&lt;/em&gt;; i.e., &lt;em&gt;⟶⁺ ∩ Id = ⊥&lt;/em&gt;.&lt;br&gt; - An acyclic graph is a (&lt;em&gt;directed) forest&lt;/em&gt; exactly when ⟶ is injective; i.e.,&lt;br&gt;  every node has at most one predecessor; i.e., &lt;em&gt;⟶ ⨾ ⟵ ⊆ Id&lt;/em&gt;.&lt;br&gt;+ A node &lt;em&gt;r&lt;/em&gt; is a &lt;em&gt;root&lt;/em&gt; exactly when every node is reachable from it; i.e., &lt;em&gt;{r} × V ⊆ ⟶⋆;&lt;/em&gt;&lt;br&gt; i.e., &lt;em&gt;𝕃 r ⨾ ⟶⋆ = ⊤&lt;/em&gt; where &lt;em&gt;𝕃 r&lt;/em&gt; is defined by &lt;em&gt;𝕃 r = (ℝ r)˘&lt;/em&gt; and &lt;em&gt;x 〔ℝ r〕 y  ≡  x = r&lt;/em&gt;.&lt;br&gt; - &lt;em&gt;x〔𝕃 r ⨾ R〕 y  ≡  r〔R〕 y&lt;/em&gt; and &lt;em&gt;x 〔R ⨾ ℝ r〕 y  ≡  x 〔R〕 r&lt;/em&gt;&lt;br&gt; - A &lt;em&gt;tree&lt;/em&gt; is a forest with a root.&lt;br&gt;+ A graph is &lt;em&gt;loop free&lt;/em&gt; exactly when &lt;em&gt;⟶ ⊆ ∼Id&lt;/em&gt;.&lt;br&gt;+ A graph is &lt;em&gt;strongly connected&lt;/em&gt; exactly when &lt;em&gt;⟶⋆ = ⊤&lt;/em&gt;; i.e., &lt;em&gt;∼Id ⊆ ⟶⁺&lt;/em&gt;;&lt;br&gt; i.e., every point is reachable from any &lt;em&gt;other&lt;/em&gt; point; i.e., &lt;em&gt;∼Id ⊆ ⟶ ∩ ⟵˘&lt;/em&gt;;&lt;br&gt; i.e., any two distinct points lie on an undirected circuit.&lt;br&gt; - The equivalence classes of &lt;em&gt;⟶⋆ ∩ ⟵⋆&lt;/em&gt; are the &lt;em&gt;strongly connected components&lt;/em&gt;.&lt;br&gt;+ &lt;em&gt;Terminal∣sinks&lt;/em&gt; are nodes from which it is &lt;em&gt;not&lt;/em&gt; possible to proceed &lt;em&gt;any&lt;/em&gt; further;&lt;br&gt; i.e., terminals have no successors; the domain of &lt;em&gt;∼(⟶ ⨾ ⊤)&lt;/em&gt; is all terminals.&lt;br&gt;+ &lt;em&gt;Initial∣sources&lt;/em&gt; are nodes from which it is &lt;em&gt;not&lt;/em&gt; possible to proceed backward;&lt;br&gt; i.e., initials have no predecessors; the domain of &lt;em&gt;∼(⟵ ⨾ ⊤)&lt;/em&gt; is all initials.">
        Graph</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Graph</h3>
          <p>A <i>(Partial, resp. Total) Graph</i> \(G = (V, E,
          src, tgt)\) consists of</p>
          <ul class="org-ul">
            <li>\(V\), a set of “points, nodes, vertices”</li>
            <li>\(E\), a set of “arcs, edges”</li>
            <li>\(src, tgt : E ↔ V\), a pair of <i>partial (resp.
            total)</i> functions.</li>
          </ul>
          <p>⟦ Tersely put, in any category, a <i>graph</i> is a
          parallel pair of morphisms. ⟧</p>
          <p><i>Edge parallelism</i> is the relation \(Ξ = src ⨾
          src ˘ ∩ tgt ⨾ tgt˘\); two arcs are related when they have
          the same starting point and the same ending point, which
          both exist. Joyously, the name ‘Ξ’ is a neat reminder of
          the concept: The name is three parallel lines, for the
          concept of edge(line) parallelism.</p>
          <ul class="org-ul">
            <li>A graph is <i>total</i> exactly when <i>Id ⊆ Ξ</i>;
            and so Ξ is an equivalence.</li>
            <li>A graph has <i>no parallel arrows</i> exactly when
            <i>Ξ ⊆ Id</i>.</li>
            <li>A graph is <i>simple</i> exactly when <i>Ξ =
            Id</i>.</li>
          </ul>
          <p>The <i>associated relation</i> is the relation
          <i><span class="underline">⟶</span> = src ˘ ⨾ tgt</i>
          that relates two nodes when the first is the source of
          some edge that happens to have the second point as its
          target. One uses the associated relation to study
          properties not involving partial or parallel arrows. One
          writes <i>⟵</i> for <i>⟶˘</i>; one writes ⟶⋆ for the
          <i>reachability</i> relation.</p>
          <ul class="org-ul">
            <li>Node <i>y</i> is <i>reachable via a non-empty
            path</i> from node <i>x</i> exactly when <i>x ⟶⁺ y</i>.
              <ul class="org-ul">
                <li>Node <i>x</i> lies on a cycle exactly when <i>x
                ⟶⁺ x</i>.</li>
                <li>A graph is <i>DAG, acylic, circuit-free,</i>
                exactly when <i>⟶⁺ ⊆ ∼Id</i>; i.e., <i>⟶⁺ ∩ Id =
                ⊥</i>.</li>
                <li>An acyclic graph is a (<i>directed) forest</i>
                exactly when ⟶ is injective; i.e., every node has
                at most one predecessor; i.e., \(⟶ ⨾ ⟵ ⊆ Id\).</li>
              </ul>
            </li>
            <li>A node <i>r</i> is a <i>root</i> exactly when every
            node is reachable from it; i.e., <i>{r} × V ⊆ ⟶⋆;</i>
            i.e., <i>𝕃 r ⨾ ⟶⋆ = ⊤</i> where <i>𝕃 r</i> is defined
            by \(𝕃 r = (ℝ r)˘\) and \(x 〔ℝ r〕 y \;≡\; x = r\).
              <ul class="org-ul">
                <li>\(x〔𝕃 r ⨾ R〕 y \;≡\; r〔R〕 y\) and \(x 〔R ⨾ ℝ r〕
                y \;≡\; x 〔R〕 r\)</li>
                <li>A <i>tree</i> is a forest with a root.</li>
              </ul>
            </li>
            <li>A graph is <i>loop free</i> exactly when <i>⟶ ⊆
            ∼Id</i>.</li>
            <li>A graph is <i>strongly connected</i> exactly when
            <i>⟶⋆ = ⊤</i>; i.e., <i>∼Id ⊆ ⟶⁺</i>; i.e., every point
            is reachable from any <i>other</i> point; i.e., <i>∼Id
            ⊆ ⟶ ∩ ⟵˘</i>; i.e., any two distinct points lie on an
            undirected circuit.
              <ul class="org-ul">
                <li>The equivalence classes of <i>⟶⋆ ∩ ⟵⋆</i> are
                the <i>strongly connected components</i>.</li>
              </ul>
            </li>
            <li><i>Terminal∣sinks</i> are nodes from which it is
            <i>not</i> possible to proceed <i>any</i> further;
            i.e., terminals have no successors; the domain of
            <i>∼(⟶ ⨾ ⊤)</i> is all terminals.</li>
            <li><i>Initial∣sources</i> are nodes from which it is
            <i>not</i> possible to proceed backward; i.e., initials
            have no predecessors; the domain of <i>∼(⟵ ⨾ ⊤)</i> is
            all initials.</li>
          </ul>
        </div>
        <p><abbr class="tooltip" title=
        "An &lt;em&gt;expression&lt;/em&gt; is either a ‘variable’ or a ‘function application’; i.e., the name&lt;br&gt;of a function along with a number of existing expressions.&lt;br&gt;&lt;br&gt; Expr ::= Constant  -- E.g., 1 or “apple”&lt;br&gt;   | Variable  -- E.g., x or apple (no quotes!)&lt;br&gt;   | Application -- E.g., f(x₁, x₂, …, xₙ)&lt;br&gt;&lt;br&gt;( One reads ‘:=’ as &lt;em&gt;becomes&lt;/em&gt; and so the addition of an extra colon results in a&lt;br&gt;‘stutter’: One reads ‘∷=’ as &lt;em&gt;be-becomes&lt;/em&gt;. The symbol ‘|’ is read &lt;em&gt;or&lt;/em&gt;. )&lt;br&gt;&lt;br&gt;Notice that a constant is really just an application with &lt;em&gt;n&lt;/em&gt; being &lt;em&gt;0&lt;/em&gt; arguments&lt;br&gt;and so the first line in the definition above could be omitted.&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;In a sense, an expression is like a sentence with the variables acting as&lt;br&gt;pronouns and the function applications acting as verb clauses and the argument&lt;br&gt;to the application are the participants in the action of the verbal clause.&lt;br&gt;&lt;br&gt;A &lt;strong&gt;variable of type τ&lt;/strong&gt; is a &lt;em&gt;name&lt;/em&gt; denoting a yet unknown &lt;em&gt;value&lt;/em&gt; of type τ;&lt;br&gt;i.e., “it is a pronoun (nickname) referring to a person in the collection of people τ”.&lt;br&gt;E.g., to say &lt;em&gt;x&lt;/em&gt; is an integer variable means that we may treat it&lt;br&gt;as if it were a number whose precise value is unknown.&lt;br&gt;Then, if we let =Expr τ= refer to the expressions denoting &lt;em&gt;values&lt;/em&gt; of type τ;&lt;br&gt;then a &lt;strong&gt;meta-variable&lt;/strong&gt; is simply a normal variable of type =Expr τ=.&lt;br&gt;&lt;br&gt;That is, when we write phrases like =“Let E be an expression”=, then the &lt;em&gt;name&lt;/em&gt; &lt;EM&gt;E&lt;/EM&gt;&lt;br&gt;varies and so is a variable, but it is an expression and so may consist of a&lt;br&gt;function application or a variable. &lt;strong&gt;That is, &lt;EM&gt;E&lt;/EM&gt; is a variable that may stand&lt;br&gt;for variables.&lt;/strong&gt; This layered inception is resolved by referring to &lt;EM&gt;E&lt;/EM&gt; as not&lt;br&gt;just any normal variable, but instead as a &lt;strong&gt;meta-variable&lt;/strong&gt;: A variable capable of&lt;br&gt;referring to other (simpler) variables.&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;Expressions, as defined above, are also known as &lt;em&gt;abstract syntax trees&lt;/em&gt; (AST) or&lt;br&gt;&lt;em&gt;prefix notation&lt;/em&gt;. Then &lt;em&gt;textual substitution&lt;/em&gt; is known as ‘grafting trees’ (a&lt;br&gt;monadic bind).&lt;br&gt;&lt;br&gt;Their use can be clunky, such as by requiring many parentheses and implicitly&lt;br&gt;forcing a syntactic distinction between equivalent expressions; e.g.,&lt;br&gt;&lt;em&gt;gcd(m,gcd(n,p))&lt;/em&gt; and &lt;em&gt;gcd(gcd(m,n),p)&lt;/em&gt; look difference even though &lt;em&gt;gcd&lt;/em&gt; is&lt;br&gt;associative.&lt;br&gt;&lt;br&gt;As such, one can declare &lt;em&gt;precedence levels&lt;/em&gt; ---a.k.a. &lt;em&gt;binding power&lt;/em&gt;--- to reduce&lt;br&gt;parentheses, one can declare fixity ---i.e., have arguments around operation&lt;br&gt;names---, and, finally, one can declare association ---whether sequential&lt;br&gt;instances of an operation should be read with implicit parenthesis to the right&lt;br&gt;or the to the left--- to reduce syntactic differences. The resulting expression&lt;br&gt;are now known to be in a &lt;em&gt;concrete syntax&lt;/em&gt; ---i.e., in a syntactic shape that is&lt;br&gt;more concrete.&lt;br&gt;&lt;br&gt;That is, the &lt;strong&gt;conventions&lt;/strong&gt; on how a &lt;em&gt;string&lt;/em&gt; should be parsed as a &lt;em&gt;tree&lt;/em&gt; are known as a&lt;br&gt;&lt;strong&gt;precedence, fixity, and associativity rules.&lt;/strong&gt;&lt;br&gt;&lt;br&gt;Similarly, not for operators but one treats &lt;em&gt;relations&lt;/em&gt; &lt;strong&gt;conjunctionally&lt;/strong&gt; to reduce&lt;br&gt;the number of ‘and’(∧) symbols; e.g. &lt;em&gt;x ≤ y + 2 = z  ≡  x ≤ (y + 2)  ∧  (y + 2) = z&lt;/em&gt;.&lt;br&gt;This is very useful to avoid repeating lengthy common expressions, such as &lt;em&gt;y + 2&lt;/em&gt;.">
        Expression</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Expression</h3>
          <p>An <i>expression</i> is either a ‘variable’ or a
          ‘function application’; i.e., the name of a function
          along with a number of existing expressions.</p>
          <pre class="example" id="org7ffa0a7">
 Expr ::= Constant    -- E.g., 1 or “apple”
      |  Variable    -- E.g., x or apple (no quotes!)
      |  Application -- E.g., f(x₁, x₂, …, xₙ)
</pre>
          <p>( One reads ‘:=’ as <i>becomes</i> and so the addition
          of an extra colon results in a ‘stutter’: One reads ‘∷=’
          as <i>be-becomes</i>. The symbol ‘|’ is read <i>or</i>.
          )</p>
          <p>Notice that a constant is really just an application
          with <i>n</i> being <i>0</i> arguments and so the first
          line in the definition above could be omitted.</p>
          <hr>
          <p>In a sense, an expression is like a sentence with the
          variables acting as pronouns and the function
          applications acting as verb clauses and the argument to
          the application are the participants in the action of the
          verbal clause.</p>
          <p>A <b>variable of type τ</b> is a <i>name</i> denoting
          a yet unknown <i>value</i> of type τ; i.e., “it is a
          pronoun (nickname) referring to a person in the
          collection of people τ”. E.g., to say \(x\) is an integer
          variable means that we may treat it as if it were a
          number whose precise value is unknown. Then, if we let
          <code>Expr τ</code> refer to the expressions denoting
          <i>values</i> of type τ; then a <b>meta-variable</b> is
          simply a normal variable of type <code>Expr τ</code>.</p>
          <p>That is, when we write phrases like <code>“Let E be an
          expression”</code>, then the <i>name</i> \(E\) varies and
          so is a variable, but it is an expression and so may
          consist of a function application or a variable. <b>That
          is, \(E\) is a variable that may stand for variables.</b>
          This layered inception is resolved by referring to \(E\)
          as not just any normal variable, but instead as a
          <b>meta-variable</b>: A variable capable of referring to
          other (simpler) variables.</p>
          <hr>
          <p>Expressions, as defined above, are also known as
          <i>abstract syntax trees</i> (AST) or <i>prefix
          notation</i>. Then <i>textual substitution</i> is known
          as ‘grafting trees’ (a monadic bind).</p>
          <p>Their use can be clunky, such as by requiring many
          parentheses and implicitly forcing a syntactic
          distinction between equivalent expressions; e.g.,
          <i>gcd(m,gcd(n,p))</i> and <i>gcd(gcd(m,n),p)</i> look
          difference even though <i>gcd</i> is associative.</p>
          <p>As such, one can declare <i>precedence levels</i>
          —a.k.a. <i>binding power</i>— to reduce parentheses, one
          can declare fixity —i.e., have arguments around operation
          names—, and, finally, one can declare association
          —whether sequential instances of an operation should be
          read with implicit parenthesis to the right or the to the
          left— to reduce syntactic differences. The resulting
          expression are now known to be in a <i>concrete
          syntax</i> —i.e., in a syntactic shape that is more
          concrete.</p>
          <p>That is, the <b>conventions</b> on how a <i>string</i>
          should be parsed as a <i>tree</i> are known as a
          <b>precedence, fixity, and associativity rules.</b></p>
          <p>Similarly, not for operators but one treats
          <i>relations</i> <b>conjunctionally</b> to reduce the
          number of ‘and’(∧) symbols; e.g. \(x ≤ y + 2 = z
          \quad≡\quad x ≤ (y + 2) \,∧\, (y + 2) = z\). This is very
          useful to avoid repeating lengthy common expressions,
          such as <i>y + 2</i>.</p>
        </div>
        <p><abbr class="tooltip" title=
        "How we prove a theorem &lt;em&gt;P  n&lt;/em&gt; ranging over natural numbers &lt;em&gt;n&lt;/em&gt;?&lt;br&gt;&lt;br&gt;For instance, suppose the property &lt;EM&gt;P&lt;/EM&gt; is that using only 3 and 5 dollar bills,&lt;br&gt;any amount of money that is at-least 8 dollars can be formed.&lt;br&gt;&lt;br&gt;Since there are an infinite number of natural numbers, it is not possibly to&lt;br&gt;verify &lt;em&gt;P  n&lt;/em&gt; is true by &lt;em&gt;evaluating&lt;/em&gt; &lt;em&gt;P  n&lt;/em&gt; at each natural number &lt;em&gt;n&lt;/em&gt;.&lt;br&gt;&lt;br&gt;&lt;strong&gt;Knocking over dominos is induction:&lt;/strong&gt;&lt;br&gt;The natural numbers are like an infinite number of dominoes ---i.e., standing&lt;br&gt;tiles one after the other, in any arrangement. Can all dominoes be knocked over?&lt;br&gt;That is, if we construe &lt;em&gt;P  n&lt;/em&gt; to mean “the &lt;em&gt;n&lt;/em&gt;-th domino can be knocked over”,&lt;br&gt;then the question is “is &lt;em&gt;∀ n • P  n&lt;/em&gt; true”. Then, clearly if we can knock over&lt;br&gt;the first domino, &lt;EM&gt;P  0&lt;/EM&gt;, and if when a domino is knocked over then it also&lt;br&gt;knocks over the next domino, &lt;em&gt;P  n ⇒ P  (n + 1)&lt;/em&gt;, then ‘clearly’ all dominoes&lt;br&gt;will be knocked over. This ‘basic observation’ is known as &lt;em&gt;induction&lt;/em&gt;.&lt;br&gt;&lt;br&gt;&lt;strong&gt;Climbing a ladder is induction:&lt;/strong&gt;&lt;br&gt;The natural numbers are like an infinite ladder ascending to heaven. Can we&lt;br&gt;reach every step, rung, on the ladder? That is, if we construe &lt;em&gt;P  n&lt;/em&gt; to mean&lt;br&gt;“the &lt;em&gt;n&lt;/em&gt;-th rung is reachable”, then the question is “is &lt;em&gt;∀ n • P  n&lt;/em&gt;&lt;br&gt;true”. Then, clearly if we can reach the first rung, &lt;EM&gt;P  0&lt;/EM&gt;, and whenever we&lt;br&gt;climb to a rung then we can reach up and grab the next rung, &lt;em&gt;P  n ⇒ P  (n +&lt;br&gt;1)&lt;/em&gt;, then ‘clearly’ all rungs of the ladder can be reached. This ‘basic&lt;br&gt;observation’ is known as &lt;em&gt;induction&lt;/em&gt;.&lt;br&gt;&lt;br&gt;&lt;strong&gt;Constant functions are induction:&lt;/strong&gt;&lt;br&gt;A predicate &lt;EM&gt;P : ℕ → 𝔹&lt;/EM&gt; is a function. When is such a function constantly the&lt;br&gt;value &lt;em&gt;\true&lt;/em&gt;? That is, when is &lt;em&gt;∀ n • P  n = \true&lt;/em&gt;? Clearly, if &lt;EM&gt;P&lt;/EM&gt; starts&lt;br&gt;off being &lt;em&gt;\true&lt;/em&gt; ---i.e., &lt;em&gt;P 0&lt;/em&gt;--- and it preserves truth at every step ---i.e.,&lt;br&gt;&lt;em&gt;P n ⇒ P (n + 1)&lt;/em&gt;--- then &lt;em&gt;P n&lt;/em&gt; will be true for any choice of &lt;em&gt;n&lt;/em&gt;.&lt;br&gt;&lt;br&gt;That is, if we consider &lt;em&gt;(ℕ, ≤)&lt;/em&gt; and &lt;em&gt;(𝔹, ⇒)&lt;/em&gt; as ordered sets and &lt;EM&gt;P&lt;/EM&gt; starts at&lt;br&gt;the ‘top’ of 𝔹 ---i.e., &lt;em&gt;P 0 = true&lt;/em&gt;--- and it is ascending ---i.e., &lt;em&gt;P n ⇒ P (n +&lt;br&gt;1)&lt;/em&gt;--- and so ‘never goes down’, then clearly it must stay constantly at the top&lt;br&gt;value of 𝔹. This ‘basic observation’ is known as &lt;em&gt;induction&lt;/em&gt;.&lt;br&gt;&lt;br&gt;&lt;br&gt;⟦ For the money problem, we need to start somewhere else besides 0. ⟧&lt;br&gt;&lt;br&gt;&lt;strong&gt;Principle of (“Weak”) Mathematical Induction:&lt;/strong&gt;&lt;br&gt;To show that a property &lt;EM&gt;P&lt;/EM&gt; is true for all natural numbers starting with some&lt;br&gt;number &lt;em&gt;n_0&lt;/em&gt;, show the following two properties:&lt;br&gt;+ Base case :: Show that &lt;em&gt;P  n₀&lt;/em&gt; is true.&lt;br&gt;+ Inductive Step :: Show that whenever (the &lt;strong&gt;inductive hypothesis&lt;/strong&gt;) &lt;em&gt;n&lt;/em&gt; is a&lt;br&gt; natural number that such that &lt;em&gt;n ≥ n₀&lt;/em&gt; and &lt;em&gt;P  n&lt;/em&gt; is true, then &lt;em&gt;P  (n + 1)&lt;/em&gt;&lt;br&gt; is also true.&lt;br&gt;&lt;br&gt;⟦ For the money problem, we need to be able to use the fact that to prove&lt;br&gt;&lt;em&gt;P (n + 1)&lt;/em&gt; we must have already proven &lt;EM&gt;P&lt;/EM&gt; for all smaller values. ⟧&lt;br&gt;&lt;br&gt;&lt;strong&gt;Principle of (“Strong”) Mathematical Induction&lt;/strong&gt;:&lt;br&gt;To show that a property &lt;EM&gt;P&lt;/EM&gt; is true for all natural numbers starting with some&lt;br&gt;number &lt;em&gt;n_0&lt;/em&gt;, show the following two properties:&lt;br&gt;+ Base case :: Show that &lt;em&gt;P  n₀&lt;/em&gt; is true.&lt;br&gt;+ Inductive Step :: Show that whenever (the &lt;strong&gt;inductive hypothesis&lt;/strong&gt;) &lt;em&gt;n&lt;/em&gt; is a&lt;br&gt; natural number that such that &lt;em&gt;n ≥ n₀&lt;/em&gt; and &lt;em&gt;P  n_0, P  (n_0 + 1), P  (n_0 +&lt;br&gt; 2), …, P  n&lt;/em&gt; are true, then &lt;em&gt;P  (n + 1)&lt;/em&gt; is also true.&lt;br&gt;&lt;br&gt;⟦ The ‘strength’ of these principles refers to the strength of the inductive&lt;br&gt;hypothesis. The principles are provably equivalent. ⟧&lt;br&gt;&lt;br&gt;# (It is also a way to say that ℕ has non-empty meets.)&lt;br&gt;&lt;strong&gt;The Least Number Principle (LNP) ---Another way to see induction:&lt;/strong&gt;&lt;br&gt;Every non-empty subset of the natural numbers must have a least element,&lt;br&gt;‘obviously’. This is (strong) induction.&lt;br&gt;# Possibly infinite!&lt;br&gt;&lt;br&gt;Application of LNP to showing that algorithms terminate:&lt;br&gt;In particular, every decreasing non-negative sequence of integers&lt;br&gt;&lt;em&gt;r₀ &gt; r₁ &gt; r₂ &gt; ⋯&lt;/em&gt; must terminate.&lt;br&gt;#+end_box">
        Induction</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Induction</h3>
          <p>How we prove a theorem \(P\, n\) ranging over natural
          numbers \(n\)?</p>
          <p>For instance, suppose the property \(P\) is that using
          only 3 and 5 dollar bills, any amount of money that is
          at-least 8 dollars can be formed.</p>
          <p>Since there are an infinite number of natural numbers,
          it is not possibly to verify \(P\, n\) is true by
          <i>evaluating</i> \(P\, n\) at each natural number
          \(n\).</p>
          <p><b>Knocking over dominos is induction:</b> The natural
          numbers are like an infinite number of dominoes —i.e.,
          standing tiles one after the other, in any arrangement.
          Can all dominoes be knocked over? That is, if we construe
          \(P\, n\) to mean “the <i>n</i>-th domino can be knocked
          over”, then the question is “is \(∀ n • P\, n\) true”.
          Then, clearly if we can knock over the first domino,
          \(P\, 0\), and if when a domino is knocked over then it
          also knocks over the next domino, \(P\, n ⇒ P\, (n +
          1)\), then ‘clearly’ all dominoes will be knocked over.
          This ‘basic observation’ is known as
          <i>induction</i>.</p>
          <p><b>Climbing a ladder is induction:</b> The natural
          numbers are like an infinite ladder ascending to heaven.
          Can we reach every step, rung, on the ladder? That is, if
          we construe \(P\, n\) to mean “the <i>n</i>-th rung is
          reachable”, then the question is “is \(∀ n • P\, n\)
          true”. Then, clearly if we can reach the first rung,
          \(P\, 0\), and whenever we climb to a rung then we can
          reach up and grab the next rung, \(P\, n ⇒ P\, (n + 1)\),
          then ‘clearly’ all rungs of the ladder can be reached.
          This ‘basic observation’ is known as
          <i>induction</i>.</p>
          <p><b>Constant functions are induction:</b> A predicate
          \(P : ℕ → 𝔹\) is a function. When is such a function
          constantly the value \(\true\)? That is, when is \(∀ n •
          P\, n = \true\)? Clearly, if \(P\) starts off being
          \(\true\) —i.e., <i>P 0</i>— and it preserves truth at
          every step —i.e., <i>P n ⇒ P (n + 1)</i>— then <i>P n</i>
          will be true for any choice of \(n\).</p>
          <p>That is, if we consider \((ℕ, ≤)\) and \((𝔹, ⇒)\) as
          ordered sets and \(P\) starts at the ‘top’ of 𝔹 —i.e.,
          <i>P 0 = true</i>— and it is ascending —i.e., <i>P n ⇒ P
          (n + 1)</i>— and so ‘never goes down’, then clearly it
          must stay constantly at the top value of 𝔹. This ‘basic
          observation’ is known as <i>induction</i>.</p>
          <p>⟦ For the money problem, we need to start somewhere
          else besides 0. ⟧</p>
          <p><b>Principle of (“Weak”) Mathematical Induction:</b>
          To show that a property \(P\) is true for all natural
          numbers starting with some number \(n_0\), show the
          following two properties:</p>
          <dl class="org-dl">
            <dt>Base case</dt>
            <dd>Show that \(P\, n₀\) is true.</dd>
            <dt>Inductive Step</dt>
            <dd>Show that whenever (the <b>inductive
            hypothesis</b>) \(n\) is a natural number that such
            that \(n ≥ n₀\) and \(P\, n\) is true, then \(P\, (n +
            1)\) is also true.</dd>
          </dl>
          <p>⟦ For the money problem, we need to be able to use the
          fact that to prove \(P\,(n + 1)\) we must have already
          proven \(P\) for all smaller values. ⟧</p>
          <p><b>Principle of (“Strong”) Mathematical Induction</b>:
          To show that a property \(P\) is true for all natural
          numbers starting with some number \(n_0\), show the
          following two properties:</p>
          <dl class="org-dl">
            <dt>Base case</dt>
            <dd>Show that \(P\, n₀\) is true.</dd>
            <dt>Inductive Step</dt>
            <dd>Show that whenever (the <b>inductive
            hypothesis</b>) \(n\) is a natural number that such
            that \(n ≥ n₀\) and \(P\, n_0, P\, (n_0 + 1), P\, (n_0
            + 2), …, P\, n\) are true, then \(P\, (n + 1)\) is also
            true.</dd>
          </dl>
          <p>⟦ The ‘strength’ of these principles refers to the
          strength of the inductive hypothesis. The principles are
          provably equivalent. ⟧</p>
          <p><b>The Least Number Principle (LNP) —Another way to
          see induction:</b> Every non-empty subset of the natural
          numbers must have a least element, ‘obviously’. This is
          (strong) induction.</p>
          <p>Application of LNP to showing that algorithms
          terminate: In particular, every decreasing non-negative
          sequence of integers \(r₀ &gt; r₁ &gt; r₂ &gt; ⋯\) must
          terminate. #+end<sub>box</sub></p>
        </div>
        <p><abbr class="tooltip" title=
        "The &lt;strong&gt;(simultaneous textual) Substitution operation&lt;/strong&gt; &lt;em&gt;E[\vec x ≔ \vec F]&lt;/em&gt; replaces&lt;br&gt;all variables &lt;em&gt;\vec x&lt;/em&gt; with parenthesised expressions &lt;em&gt;\vec F&lt;/em&gt; in an expression&lt;br&gt;&lt;EM&gt;E&lt;/EM&gt;. In particular, &lt;em&gt;E[x ≔ F]&lt;/em&gt; is just &lt;EM&gt;E&lt;/EM&gt; but with all occurrences of &lt;em&gt;x&lt;/em&gt;&lt;br&gt;replaced by &lt;em&gt;“(F)”&lt;/em&gt;. This is the “find-and-replace” utility you use on your&lt;br&gt;computers.&lt;br&gt;&lt;br&gt;Textual substitution on expressions is known as “grafting” on trees: Evaluate&lt;br&gt;&lt;em&gt;E[x ≔ F]&lt;/em&gt; by going down the tree &lt;EM&gt;E&lt;/EM&gt; and finding all the ‘leaves’ labelled &lt;em&gt;x&lt;/em&gt;,&lt;br&gt;cut them out and replace them with the new trees &lt;EM&gt;F&lt;/EM&gt;.&lt;br&gt;&lt;br&gt;Since expressions are either variables of functions applications,&lt;br&gt;substitution can be defined inductively/recursively by the following two clauses:&lt;br&gt;&lt;br&gt;+ &lt;em&gt;y[x ≔ F]       = if&nbsp; x = y&nbsp; then&nbsp; F &nbsp;else&nbsp; y &nbsp;fi&lt;/em&gt;&lt;br&gt;+ &lt;em&gt;f(t₁, …, tₙ)[x ≔ F] = f(t₁′, …, tₙ′) &nbsp;where&nbsp; tᵢ′ = tᵢ[x ≔ F]&lt;/em&gt;&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;Sequential ≠ Simultaneous:&lt;br&gt; &lt;em&gt;(x + 2 · y)[x ≔ y][y ≔ x] ≠ (x + 2 · y)[x, y ≔ y, x]&lt;/em&gt;&lt;br&gt;&lt;br&gt;Python (https://alhassy.github.io/PythonCheatSheet/CheatSheet.pdf), for example, has simultaneous &lt;em&gt;assignment&lt;/em&gt;;&lt;br&gt;e.g., &lt;code&gt;x, y = y, x&lt;/code&gt; is used to swap the value of two variables.&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;A &lt;em&gt;function&lt;/em&gt; &lt;em&gt;f&lt;/em&gt; is a rule for computing a value from another value.&lt;br&gt;&lt;br&gt;If we define &lt;em&gt;f  x = E&lt;/em&gt; using an expression, then &lt;em&gt;function application&lt;/em&gt; can be&lt;br&gt;defined using textual substitution: &lt;em&gt;f   X = E[x ≔ X]&lt;/em&gt;. That is, expressions&lt;br&gt;can be considered functions of their variables ---but it is still expressions&lt;br&gt;that are the primitive idea, the building blocks.">
        Textual_Substitution</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Textual_Substitution</h3>
          <p>The <b>(simultaneous textual) Substitution
          operation</b> \(E[\vec x ≔ \vec F]\) replaces all
          variables \(\vec x\) with parenthesised expressions
          \(\vec F\) in an expression \(E\). In particular, \(E[x ≔
          F]\) is just \(E\) but with all occurrences of \(x\)
          replaced by \(“(F)”\). This is the “find-and-replace”
          utility you use on your computers.</p>
          <p>Textual substitution on expressions is known as
          “grafting” on trees: Evaluate \(E[x ≔ F]\) by going down
          the tree \(E\) and finding all the ‘leaves’ labelled
          \(x\), cut them out and replace them with the new trees
          \(F\).</p>
          <p>Since expressions are either variables of functions
          applications, substitution can be defined
          inductively/recursively by the following two clauses:</p>
          <ul class="org-ul">
            <li><i>y[x ≔ F] = if&nbsp; x = y&nbsp; then&nbsp; F
            &nbsp;else&nbsp; y &nbsp;fi</i></li>
            <li><i>f(t₁, …, tₙ)[x ≔ F] = f(t₁′, …, tₙ′)
            &nbsp;where&nbsp; tᵢ′ = tᵢ[x ≔ F]</i></li>
          </ul>
          <hr>
          <p>Sequential ≠ Simultaneous: <i>(x + 2 · y)[x ≔ y][y ≔
          x] ≠ (x + 2 · y)[x, y ≔ y, x]</i></p>
          <p><a href=
          "https://alhassy.github.io/PythonCheatSheet/CheatSheet.pdf">
          Python</a>, for example, has simultaneous
          <i>assignment</i>; e.g., <code>x, y = y, x</code> is used
          to swap the value of two variables.</p>
          <hr>
          <p>A <i>function</i> \(f\) is a rule for computing a
          value from another value.</p>
          <p>If we define \(f\, x = E\) using an expression, then
          <i>function application</i> can be defined using textual
          substitution: \(f \, X = E[x ≔ X]\). That is, expressions
          can be considered functions of their variables —but it is
          still expressions that are the primitive idea, the
          building blocks.</p>
        </div>
        <p><abbr class="tooltip" title=
        "Formally, a “proof” is obtained by applying a number of “rules” to known results&lt;br&gt;to obtain new results; a “theorem” is the conclusion of a “proof”. An “axiom”&lt;br&gt;is a rule that does not need to be applied to any existing results: It's just a&lt;br&gt;known result.&lt;br&gt;&lt;br&gt;That is, a &lt;strong&gt;rule&lt;/strong&gt; &lt;EM&gt;R&lt;/EM&gt; is a tuple &lt;EM&gt;P₁, …, Pₙ, C&lt;/EM&gt; that is thought of as ‘taking&lt;br&gt;&lt;strong&gt;premises&lt;/strong&gt; (instances of known results) &lt;EM&gt;Pᵢ&lt;/EM&gt;’ and acting as a ‘natural,&lt;br&gt;reasonable justification’ to obtain &lt;strong&gt;conclusion&lt;/strong&gt; &lt;EM&gt;C&lt;/EM&gt;. A &lt;strong&gt;proof system&lt;/strong&gt; is a&lt;br&gt;collection of rules. At first sight, this all sounds very abstract and rather&lt;br&gt;useless, however it is a &lt;em&gt;game&lt;/em&gt;: &lt;strong&gt;Starting from rules, what can you obtain?&lt;/strong&gt; Some&lt;br&gt;games can be very fun! Another way to see these ideas is from the view of&lt;br&gt;programming:&lt;br&gt;&lt;br&gt;+ Proving ≈ Programming&lt;br&gt;+ Logic  ≈ Trees (algebraic data types, 𝒲-types)&lt;br&gt;+ Rules  ≈ Constructors&lt;br&gt;+ Proof  ≈ An application of constructors&lt;br&gt;+ Axiom  ≈ A constructor with no arguments&lt;br&gt;&lt;br&gt;Just as in elementary school one sees addition ‘+’ as a fraction with the&lt;br&gt;arguments above the horizontal line and their sum below the line, so too is that&lt;br&gt;notation reused for inference rules: Premises are above the fraction's bar and&lt;br&gt;the conclusion is below.&lt;br&gt;                  12&lt;br&gt;P₁, P₂, …, Pn          + 7&lt;br&gt;&lt;hr&gt;R   versues   ----&lt;br&gt;   C              19&lt;br&gt;&lt;br&gt;Just as there are meta-variables and meta-theorems, there is ‘meta-syntax’:&lt;br&gt;- The use of a fraction to delimit premises from conclusion is a form of ‘implication’.&lt;br&gt;- The use of a comma, or white space, to separate premises is a form of ‘conjunction’.&lt;br&gt;&lt;br&gt;If our expressions actually have an implication and conjunction operation, then&lt;br&gt;inference rule above can be presented as an axiom &lt;EM&gt;P₁  ∧  ⋯  ∧  Pₙ  ⇒  C&lt;/EM&gt;.&lt;br&gt;&lt;br&gt;The inference rule says “if the &lt;EM&gt;Pᵢ&lt;/EM&gt; are all valid, i.e., true in &lt;em&gt;all states&lt;/em&gt;,&lt;br&gt;then so is &lt;EM&gt;C&lt;/EM&gt;”; the axiom, on the other hand, says “if the &lt;EM&gt;Pᵢ&lt;/EM&gt; are true in &lt;em&gt;a&lt;br&gt;state&lt;/em&gt;, then &lt;EM&gt;C&lt;/EM&gt; is true in &lt;em&gt;that state&lt;/em&gt;.” Thus the rule and the axiom are not&lt;br&gt;quite the same.&lt;br&gt;&lt;br&gt;Moreover, the rule is not a Boolean expression. Rules are thus more general,&lt;br&gt;allowing us to construct systems of reasoning that have no concrete notions of&lt;br&gt;‘truth’ ---e.g., the above arithmetic rule says from the things above the&lt;br&gt;fraction bar, using the operation ‘+’, we &lt;em&gt;can get&lt;/em&gt; the thing below the bar, but&lt;br&gt;that thing (19) is not ‘true’ as we may think of conventional truth.&lt;br&gt;&lt;br&gt;Finally, the rule asserts that &lt;EM&gt;C&lt;/EM&gt; follows from &lt;EM&gt;P₁, …, Pₙ&lt;/EM&gt;. The formula &lt;em&gt;P₁&lt;br&gt; ∧  ⋯  ∧  Pₙ  ⇒  C&lt;/em&gt;, on the other hand, is an expression (but it need not&lt;br&gt;be a theorem).&lt;br&gt;&lt;br&gt;A “theorem” is a syntactic concept: Can we play the game of moving symbols to&lt;br&gt;get this? Not “is the meaning of this true”! ‘Semantic concepts’ rely on&lt;br&gt;‘states’, assignments of values to variables so that we can ‘evaluate, simplify’&lt;br&gt;statements to deduce if they are true.&lt;br&gt;&lt;br&gt;Syntax is like static analysis; semantics is like actually running the program&lt;br&gt;(on some, or all possible inputs).&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;One reads/writes a &lt;em&gt;natural deduction proof (tree)&lt;/em&gt; from the very &lt;strong&gt;bottom&lt;/strong&gt;: Each&lt;br&gt;line is an application of a rule of reasoning, whose assumptions are above the&lt;br&gt;line; so read/written upward. The &lt;strong&gt;benefit&lt;/strong&gt; of this approach is that &lt;strong&gt;rules guide&lt;br&gt;proof construction&lt;/strong&gt;; i.e., it is goal-directed.&lt;br&gt;&lt;br&gt;However the &lt;strong&gt;downsides are numerous&lt;/strong&gt;:&lt;br&gt;- So much horizontal space is needed even for simple proofs.&lt;br&gt;- One has to &lt;strong&gt;repeat&lt;/strong&gt; common subexpressions; e.g., when using transitivity of equality.&lt;br&gt;- For comparison with other proof notations, such as Hilbert style,&lt;br&gt; see Prolog (http://www.cse.yorku.ca/~logicE/misc/logicE_intro.pdf][Equational Propositional Logic]].&lt;br&gt;&lt;br&gt; This is more ‘linear’ proof format; also known as &lt;em&gt;equational style&lt;/em&gt; or&lt;br&gt; &lt;em&gt;calculational proof&lt;/em&gt;. This corresponds to the ‘high-school style’ of writing a&lt;br&gt; sequence of equations, one on each line, along with hints/explanations of how&lt;br&gt; each line was reached from the previous line.&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;Finally, an inference rule says that it is possible to start with the givens&lt;br&gt;&lt;EM&gt;Pᵢ&lt;/EM&gt; and obtain as result &lt;EM&gt;C&lt;/EM&gt;. The idea to use &lt;strong&gt;inference rules as computation&lt;/strong&gt;&lt;br&gt;is witnessed by the [[https://alhassy.github.io/PrologCheatSheet/CheatSheet.pdf) programming language.">
        Inference_Rule</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Inference_Rule</h3>
          <p>Formally, a “proof” is obtained by applying a number
          of “rules” to known results to obtain new results; a
          “theorem” is the conclusion of a “proof”. An “axiom” is a
          rule that does not need to be applied to any existing
          results: It’s just a known result.</p>
          <p>That is, a <b>rule</b> \(R\) is a tuple \(P₁, …, Pₙ,
          C\) that is thought of as ‘taking <b>premises</b>
          (instances of known results) \(Pᵢ\)’ and acting as a
          ‘natural, reasonable justification’ to obtain
          <b>conclusion</b> \(C\). A <b>proof system</b> is a
          collection of rules. At first sight, this all sounds very
          abstract and rather useless, however it is a <i>game</i>:
          <b>Starting from rules, what can you obtain?</b> Some
          games can be very fun! Another way to see these ideas is
          from the view of programming:</p>
          <ul class="org-ul">
            <li>Proving ≈ Programming</li>
            <li>Logic ≈ Trees (algebraic data types, 𝒲-types)</li>
            <li>Rules ≈ Constructors</li>
            <li>Proof ≈ An application of constructors</li>
            <li>Axiom ≈ A constructor with no arguments</li>
          </ul>
          <p>Just as in elementary school one sees addition ‘+’ as
          a fraction with the arguments above the horizontal line
          and their sum below the line, so too is that notation
          reused for inference rules: Premises are above the
          fraction’s bar and the conclusion is below.</p>
          <pre class="example" id="org616448d">
                                   12
P₁, P₂, …, Pn                    +  7
---------------R     versues     ----
      C                            19
</pre>
          <p>Just as there are meta-variables and meta-theorems,
          there is ‘meta-syntax’:</p>
          <ul class="org-ul">
            <li>The use of a fraction to delimit premises from
            conclusion is a form of ‘implication’.</li>
            <li>The use of a comma, or white space, to separate
            premises is a form of ‘conjunction’.</li>
          </ul>
          <p>If our expressions actually have an implication and
          conjunction operation, then inference rule above can be
          presented as an axiom \(P₁ \,∧\, ⋯ \,∧\, Pₙ \,⇒\,
          C\).</p>
          <p>The inference rule says “if the \(Pᵢ\) are all valid,
          i.e., true in <i>all states</i>, then so is \(C\)”; the
          axiom, on the other hand, says “if the \(Pᵢ\) are true in
          <i>a state</i>, then \(C\) is true in <i>that state</i>.”
          Thus the rule and the axiom are not quite the same.</p>
          <p>Moreover, the rule is not a Boolean expression. Rules
          are thus more general, allowing us to construct systems
          of reasoning that have no concrete notions of ‘truth’
          —e.g., the above arithmetic rule says from the things
          above the fraction bar, using the operation ‘+’, we
          <i>can get</i> the thing below the bar, but that thing
          (19) is not ‘true’ as we may think of conventional
          truth.</p>
          <p>Finally, the rule asserts that \(C\) follows from
          \(P₁, …, Pₙ\). The formula \(P₁ \,∧\, ⋯ \,∧\, Pₙ \,⇒\,
          C\), on the other hand, is an expression (but it need not
          be a theorem).</p>
          <p>A “theorem” is a syntactic concept: Can we play the
          game of moving symbols to get this? Not “is the meaning
          of this true”! ‘Semantic concepts’ rely on ‘states’,
          assignments of values to variables so that we can
          ‘evaluate, simplify’ statements to deduce if they are
          true.</p>
          <p>Syntax is like static analysis; semantics is like
          actually running the program (on some, or all possible
          inputs).</p>
          <hr>
          <p>One reads/writes a <i>natural deduction proof
          (tree)</i> from the very <b>bottom</b>: Each line is an
          application of a rule of reasoning, whose assumptions are
          above the line; so read/written upward. The
          <b>benefit</b> of this approach is that <b>rules guide
          proof construction</b>; i.e., it is goal-directed.</p>
          <p>However the <b>downsides are numerous</b>:</p>
          <ul class="org-ul">
            <li>So much horizontal space is needed even for simple
            proofs.</li>
            <li>One has to <b>repeat</b> common subexpressions;
            e.g., when using transitivity of equality.</li>
            <li>
              <p>For comparison with other proof notations, such as
              Hilbert style, see <a href=
              "http://www.cse.yorku.ca/~logicE/misc/logicE_intro.pdf">
              Equational Propositional Logic</a>.</p>
              <p>This is more ‘linear’ proof format; also known as
              <i>equational style</i> or <i>calculational
              proof</i>. This corresponds to the ‘high-school
              style’ of writing a sequence of equations, one on
              each line, along with hints/explanations of how each
              line was reached from the previous line.</p>
            </li>
          </ul>
          <hr>
          <p>Finally, an inference rule says that it is possible to
          start with the givens \(Pᵢ\) and obtain as result \(C\).
          The idea to use <b>inference rules as computation</b> is
          witnessed by the <a href=
          "https://alhassy.github.io/PrologCheatSheet/CheatSheet.pdf">
          Prolog</a> programming language.</p>
        </div>
        <p><abbr class="tooltip" title=
        "A &lt;em&gt;logic&lt;/em&gt; is a formal system of reasoning...&lt;br&gt;&lt;br&gt;A &lt;em&gt;logic&lt;/em&gt; is a set of symbols along with a set of &lt;em&gt;formulas&lt;/em&gt; formed from the&lt;br&gt;symbols, and a set of &lt;em&gt;inference rules&lt;/em&gt; which allow formulas to be derived from&lt;br&gt;other formulas. (The formulas may or may not include a notion of variable.)&lt;br&gt;&lt;br&gt;Logics are purely syntactic objects; an &lt;em&gt;inference rule&lt;/em&gt; is a syntactic mechanism&lt;br&gt;for deriving “truths” or “theorems”.&lt;br&gt;&lt;br&gt;In general, proofs are evidence of truth of a claim; by demonstrating that the&lt;br&gt;claim follows from some &lt;em&gt;obvious truth&lt;/em&gt; using rules of reasoning that &lt;em&gt;obviously&lt;br&gt;preserve truth.&lt;/em&gt;">
        Logic</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Logic</h3>
          <p>A <i>logic</i> is a formal system of reasoning…</p>
          <p>A <i>logic</i> is a set of symbols along with a set of
          <i>formulas</i> formed from the symbols, and a set of
          <i>inference rules</i> which allow formulas to be derived
          from other formulas. (The formulas may or may not include
          a notion of variable.)</p>
          <p>Logics are purely syntactic objects; an <i>inference
          rule</i> is a syntactic mechanism for deriving “truths”
          or “theorems”.</p>
          <p>In general, proofs are evidence of truth of a claim;
          by demonstrating that the claim follows from some
          <i>obvious truth</i> using rules of reasoning that
          <i>obviously preserve truth.</i></p>
        </div>
        <p><abbr class="tooltip" title=
        "A &lt;em&gt;theorem&lt;/em&gt; is a syntactic object, a string of symbols with a particular property.&lt;br&gt;&lt;br&gt;A &lt;em&gt;theorem&lt;/em&gt; of a calculus is either an axiom or the conclusion of an inference&lt;br&gt;rule whose premises are theorems.&lt;br&gt;&lt;br&gt;Different axioms could lead to the same set of theorems, and many texts use&lt;br&gt;different axioms.&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;A “theorem” is a syntactic concept: Can we play the game of moving symbols to&lt;br&gt;get this? Not “is the meaning of this true”! ‘Semantic concepts’ rely on&lt;br&gt;‘states’, assignments of values to variables so that we can ‘evaluate, simplify’&lt;br&gt;statements to deduce if they are true.&lt;br&gt;&lt;br&gt;Syntax is like static analysis; semantics is like actually running the program&lt;br&gt;(on some, or all possible inputs).&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;A &lt;strong&gt;meta-theorem&lt;/strong&gt; is a general statement about our logic that we prove to be&lt;br&gt;true. That is, if 𝑬 is collection of rules that allows us to find truths, then a&lt;br&gt;&lt;em&gt;theorem&lt;/em&gt; is a truth found using those rules; whereas a meta-theorem/ is property&lt;br&gt;of 𝑬 itself, such as what theorems it can have. That is, theorems are _in_ 𝑬 and&lt;br&gt;meta-theorems are _about_ 𝑬. For example, here is a meta-theorem that the&lt;br&gt;equational logic 𝑬 has (as do many other theories, such as lattices): An&lt;br&gt;&lt;em&gt;equational&lt;/em&gt; theorem is true precisely when its ‘dual’ is true. Such metatheorems&lt;br&gt;can be helpful to discover new theorems.&lt;br&gt;&lt;br&gt;# A meta-theorem is a theorem about theorems.">
        Theorem</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Theorem</h3>
          <p>A <i>theorem</i> is a syntactic object, a string of
          symbols with a particular property.</p>
          <p>A <i>theorem</i> of a calculus is either an axiom or
          the conclusion of an inference rule whose premises are
          theorems.</p>
          <p>Different axioms could lead to the same set of
          theorems, and many texts use different axioms.</p>
          <hr>
          <p>A “theorem” is a syntactic concept: Can we play the
          game of moving symbols to get this? Not “is the meaning
          of this true”! ‘Semantic concepts’ rely on ‘states’,
          assignments of values to variables so that we can
          ‘evaluate, simplify’ statements to deduce if they are
          true.</p>
          <p>Syntax is like static analysis; semantics is like
          actually running the program (on some, or all possible
          inputs).</p>
          <hr>
          <p>A <b>meta-theorem</b> is a general statement about our
          logic that we prove to be true. That is, if 𝑬 is
          collection of rules that allows us to find truths, then a
          <i>theorem</i> is a truth found using those rules;
          whereas a meta-theorem/ is property of 𝑬 itself, such as
          what theorems it can have. That is, theorems are
          <span class="underline">in</span> 𝑬 and meta-theorems are
          <span class="underline">about</span> 𝑬. For example, here
          is a meta-theorem that the equational logic 𝑬 has (as do
          many other theories, such as lattices): An
          <i>equational</i> theorem is true precisely when its
          ‘dual’ is true. Such metatheorems can be helpful to
          discover new theorems.</p>
        </div>
        <p><abbr class="tooltip" title=
        "A &lt;em&gt;theorem&lt;/em&gt; in the technical sense is an expression derived&lt;br&gt;from axioms using inference rules.&lt;br&gt;&lt;br&gt;A &lt;em&gt;metatheorem&lt;/em&gt; is a general &lt;strong&gt;statement&lt;/strong&gt; about a logic that&lt;br&gt;one argues to be &lt;strong&gt;true&lt;/strong&gt;.&lt;br&gt;&lt;br&gt;For instance, “any two theorems are equivalent” is a statement that speaks about&lt;br&gt;expressions which happen to be theorems. A logic may not have the linguistic&lt;br&gt;capability to speak of its own expressions and so the statement may not be&lt;br&gt;expressible as an expression &lt;strong&gt;within&lt;/strong&gt; the logic ---and so cannot be a theorem of&lt;br&gt;the logic.&lt;br&gt;&lt;br&gt;For instance, the logic 𝒑𝑞 has expressions formed from the symbols “𝒑”, “𝒒”, and&lt;br&gt;“-” (dash). It has the axiom schema &lt;em&gt;x𝒑-𝒒x-&lt;/em&gt; and the rule “If &lt;em&gt;x𝒑y𝒒z&lt;/em&gt; is a theorem&lt;br&gt;then so is &lt;em&gt;x-𝒑y-𝒒z-&lt;/em&gt;”. Notice that &lt;em&gt;x, y, z&lt;/em&gt; are &lt;em&gt;any&lt;/em&gt; strings of dashes;&lt;br&gt;the language of this logic does not have variables and so cannot even speak&lt;br&gt;of its own expressions, let alone its own theorems!&lt;br&gt;&lt;br&gt;[Informal] theorems about [technical, logic-specific] theorems are thus termed&lt;br&gt;‘metatheorems’.">
        Metatheorem</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Metatheorem</h3>
          <p>A <i>theorem</i> in the technical sense is an
          expression derived from axioms using inference rules.</p>
          <p>A <i>metatheorem</i> is a general <b>statement</b>
          about a logic that one argues to be <b>true</b>.</p>
          <p>For instance, “any two theorems are equivalent” is a
          statement that speaks about expressions which happen to
          be theorems. A logic may not have the linguistic
          capability to speak of its own expressions and so the
          statement may not be expressible as an expression
          <b>within</b> the logic —and so cannot be a theorem of
          the logic.</p>
          <p>For instance, the logic 𝒑𝑞 has expressions formed from
          the symbols “𝒑”, “𝒒”, and “-” (dash). It has the axiom
          schema \(x𝒑-𝒒x-\) and the rule “If \(x𝒑y𝒒z\) is a theorem
          then so is \(x-𝒑y-𝒒z-\)”. Notice that \(x, y, z\) are
          <i>any</i> strings of dashes; the language of this logic
          does not have variables and so cannot even speak of its
          own expressions, let alone its own theorems!</p>
          <p>[Informal] theorems about [technical, logic-specific]
          theorems are thus termed ‘metatheorems’.</p>
        </div>
        <p><abbr class="tooltip" title=
        "A &lt;em&gt;calculus&lt;/em&gt; is a method or process of reasoning by calculation&lt;br&gt;with symbols. A &lt;em&gt;propositional calculus&lt;/em&gt; is a method of calculating with Boolean&lt;br&gt;(or propositional) expressions.&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;Calculus: Formalised reasoning through calculation.&lt;br&gt;&lt;br&gt;‘Hand wavy’ English arguments tend to favour case analysis —considering what&lt;br&gt;could happen in each possible scenario— which increases exponentially with each&lt;br&gt;variable; in contrast, equality-based calculation is much simpler since it&lt;br&gt;delegates intricate case analysis into codified algebraic laws.">
        Calculus</abbr> (<abbr class="tooltip" title=
        "A &lt;em&gt;calculus&lt;/em&gt; is a method or process of reasoning by calculation&lt;br&gt;with symbols. A &lt;em&gt;propositional calculus&lt;/em&gt; is a method of calculating with Boolean&lt;br&gt;(or propositional) expressions.&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;Calculus: Formalised reasoning through calculation.&lt;br&gt;&lt;br&gt;‘Hand wavy’ English arguments tend to favour case analysis —considering what&lt;br&gt;could happen in each possible scenario— which increases exponentially with each&lt;br&gt;variable; in contrast, equality-based calculation is much simpler since it&lt;br&gt;delegates intricate case analysis into codified algebraic laws.">Propositional
        Calculus</abbr>)</p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Calculus</h3>
          <p>A <i>calculus</i> is a method or process of reasoning
          by calculation with symbols. A <i>propositional
          calculus</i> is a method of calculating with Boolean (or
          propositional) expressions.</p>
          <hr>
          <p>Calculus: Formalised reasoning through
          calculation.</p>
          <p>‘Hand wavy’ English arguments tend to favour case
          analysis —considering what could happen in each possible
          scenario— which increases exponentially with each
          variable; in contrast, equality-based calculation is much
          simpler since it delegates intricate case analysis into
          codified algebraic laws.</p>
        </div>
        <p><abbr class="tooltip" title=
        "&lt;strong&gt;Syntax&lt;/strong&gt; refers to the structure of expressions, or the rules for putting symbols&lt;br&gt;together to form an expression. &lt;strong&gt;Semantics&lt;/strong&gt; refers to the meaning of expressions&lt;br&gt;or how they are evaluated.&lt;br&gt;&lt;br&gt;Abstractions express something shared by their instances, such as the kinds of&lt;br&gt;operations one can perform. However, abstractions don't, by themselves, “mean”&lt;br&gt;anything! E.g., for Haskell, the &lt;code&gt;Monad&lt;/code&gt; type class does not mean anything, but&lt;br&gt;for the &lt;code&gt;Maybe&lt;/code&gt; implementation it means short-circuit sequencing and for the &lt;code&gt;List&lt;/code&gt;&lt;br&gt;implementation it means (possibly nested) iteration.&lt;br&gt;Abstractions for operations are also known as “design patterns”.&lt;br&gt;( With judicious use of Yoneda, things always denote/mean certain actions. )&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;An expression can contain variables, and evaluating such an expression requires&lt;br&gt;knowing what values to use for these variables; i.e., a &lt;strong&gt;state&lt;/strong&gt;: A list of&lt;br&gt;variables with associated values. E.g., evaluation of &lt;em&gt;x - y + 2&lt;/em&gt; in the state&lt;br&gt;consisting of &lt;em&gt;(x, 5)&lt;/em&gt; and &lt;em&gt;(y, 6)&lt;/em&gt; is performed by replacing &lt;em&gt;x&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt; by&lt;br&gt;their values to yield &lt;em&gt;5 - 6 + 2&lt;/em&gt; and then evaluating that to yield &lt;em&gt;1&lt;/em&gt;.&lt;br&gt;&lt;br&gt;A Boolean expression &lt;EM&gt;P&lt;/EM&gt; is &lt;strong&gt;satisfied&lt;/strong&gt; in a state if its value is &lt;em&gt;true&lt;/em&gt; in that&lt;br&gt;state; &lt;EM&gt;P&lt;/EM&gt; is &lt;strong&gt;satisfiable&lt;/strong&gt; if there is a state in which it is satisfied; and &lt;EM&gt;P&lt;/EM&gt;&lt;br&gt;is &lt;strong&gt;valid&lt;/strong&gt; (or is a &lt;strong&gt;tautology&lt;/strong&gt;) if it is satisfied in every state.&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;Often operations are defined by how they are evaluated (&lt;strong&gt;operationally&lt;/strong&gt;), we can&lt;br&gt;take the alternative route of defining operations by how they can be manipulated&lt;br&gt;(&lt;strong&gt;axiomatically&lt;/strong&gt;); i.e., by what properties they satisfy.&lt;br&gt;&lt;br&gt;For example, evaluation of the expression &lt;EM&gt;X = Y&lt;/EM&gt; in a state yields the value&lt;br&gt;&lt;em&gt;true&lt;/em&gt; if expressions &lt;EM&gt;X&lt;/EM&gt; and &lt;EM&gt;Y&lt;/EM&gt; have the same value and yields &lt;em&gt;false&lt;/em&gt; if they&lt;br&gt;have different values. This characterisation of equality is in terms of&lt;br&gt;expression &lt;em&gt;evaluation&lt;/em&gt;. For &lt;em&gt;reasoning about expressions&lt;/em&gt;, a more useful&lt;br&gt;characterisation would be a set of &lt;em&gt;laws&lt;/em&gt; that can be used to show that two&lt;br&gt;expressions are equal, &lt;strong&gt;without&lt;/strong&gt; calculating their values.&lt;br&gt;--- c.f., static analysis versues running a program.&lt;br&gt;&lt;br&gt;For example, you know that &lt;em&gt;x = y&lt;/em&gt; equals &lt;em&gt;y = x&lt;/em&gt;, regardless of the values of&lt;br&gt;&lt;em&gt;x&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt;. A collection of such laws can be regarded as a definition of&lt;br&gt;equality, &lt;strong&gt;provided&lt;/strong&gt; two expressions have the same value in all states precisely&lt;br&gt;when one expression can be translated into the other according to the laws.&lt;br&gt;&lt;br&gt;Usually, in &lt;em&gt;a&lt;/em&gt; logic, theorems correspond to expressions that are true in all&lt;br&gt;states.&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;That is, instead of defining expressions by how they are evaluated, we may&lt;br&gt;define expressions in terms of how they can be manipulated ---c.f., a calculus.&lt;br&gt;&lt;br&gt;For instance, we may define basic manipulative properties of operators ---i.e.,&lt;br&gt;&lt;em&gt;axioms&lt;/em&gt;--- by considering how the operators behave operationally on particular&lt;br&gt;expressions. That is, one may use an operational, intuitive, approach to obtain&lt;br&gt;an axiomatic specification (characterisation, interface) of the desired&lt;br&gt;properties.&lt;br&gt;&lt;br&gt;More concretely, since &lt;em&gt;(p ≡ q) ≡ r&lt;/em&gt; and &lt;em&gt;p ≡ (q ≡ r)&lt;/em&gt; evaluate to&lt;br&gt;the same value for any choice of values for &lt;em&gt;p, q, r&lt;/em&gt;, we may insist that a part&lt;br&gt;of the definition of equivalence is that it be an associative operation.&lt;br&gt;&lt;br&gt;Sometimes a single axiom is not enough to ‘pin down’ a unique operator ---i.e.,&lt;br&gt;to ensure we actually have a well-defined operation--- and other times this is&lt;br&gt;cleanly possible; e.g., given an ordering ‘≤’(‘⇒, ⊆, ⊑’) we can define minima&lt;br&gt;‘↓’ (‘∧, ∩, ⊓’) by the axiom: “x ↓ y is the greatest lower bound”;&lt;br&gt;i.e., &lt;em&gt;z ≤ x ↓ y  ≡  z ≤ x  ∧  z ≤ y&lt;/em&gt;.">
        Semantics</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Semantics</h3>
          <p><b>Syntax</b> refers to the structure of expressions,
          or the rules for putting symbols together to form an
          expression. <b>Semantics</b> refers to the meaning of
          expressions or how they are evaluated.</p>
          <p>Abstractions express something shared by their
          instances, such as the kinds of operations one can
          perform. However, abstractions don’t, by themselves,
          “mean” anything! E.g., for Haskell, the
          <code>Monad</code> type class does not mean anything, but
          for the <code>Maybe</code> implementation it means
          short-circuit sequencing and for the <code>List</code>
          implementation it means (possibly nested) iteration.
          Abstractions for operations are also known as “design
          patterns”. ( With judicious use of Yoneda, things always
          denote/mean certain actions. )</p>
          <hr>
          <p>An expression can contain variables, and evaluating
          such an expression requires knowing what values to use
          for these variables; i.e., a <b>state</b>: A list of
          variables with associated values. E.g., evaluation of \(x
          - y + 2\) in the state consisting of \((x, 5)\) and \((y,
          6)\) is performed by replacing \(x\) and \(y\) by their
          values to yield \(5 - 6 + 2\) and then evaluating that to
          yield \(1\).</p>
          <p>A Boolean expression \(P\) is <b>satisfied</b> in a
          state if its value is <i>true</i> in that state; \(P\) is
          <b>satisfiable</b> if there is a state in which it is
          satisfied; and \(P\) is <b>valid</b> (or is a
          <b>tautology</b>) if it is satisfied in every state.</p>
          <hr>
          <p>Often operations are defined by how they are evaluated
          (<b>operationally</b>), we can take the alternative route
          of defining operations by how they can be manipulated
          (<b>axiomatically</b>); i.e., by what properties they
          satisfy.</p>
          <p>For example, evaluation of the expression \(X = Y\) in
          a state yields the value <i>true</i> if expressions \(X\)
          and \(Y\) have the same value and yields <i>false</i> if
          they have different values. This characterisation of
          equality is in terms of expression <i>evaluation</i>. For
          <i>reasoning about expressions</i>, a more useful
          characterisation would be a set of <i>laws</i> that can
          be used to show that two expressions are equal,
          <b>without</b> calculating their values. — c.f., static
          analysis versues running a program.</p>
          <p>For example, you know that \(x = y\) equals \(y = x\),
          regardless of the values of \(x\) and \(y\). A collection
          of such laws can be regarded as a definition of equality,
          <b>provided</b> two expressions have the same value in
          all states precisely when one expression can be
          translated into the other according to the laws.</p>
          <p>Usually, in <i>a</i> logic, theorems correspond to
          expressions that are true in all states.</p>
          <hr>
          <p>That is, instead of defining expressions by how they
          are evaluated, we may define expressions in terms of how
          they can be manipulated —c.f., a calculus.</p>
          <p>For instance, we may define basic manipulative
          properties of operators —i.e., <i>axioms</i>— by
          considering how the operators behave operationally on
          particular expressions. That is, one may use an
          operational, intuitive, approach to obtain an axiomatic
          specification (characterisation, interface) of the
          desired properties.</p>
          <p>More concretely, since \((p ≡ q) ≡ r\) and \(p ≡ (q ≡
          r)\) evaluate to the same value for any choice of values
          for \(p, q, r\), we may insist that a part of the
          definition of equivalence is that it be an associative
          operation.</p>
          <p>Sometimes a single axiom is not enough to ‘pin down’ a
          unique operator —i.e., to ensure we actually have a
          well-defined operation— and other times this is cleanly
          possible; e.g., given an ordering ‘≤’(‘⇒, ⊆, ⊑’) we can
          define minima ‘↓’ (‘∧, ∩, ⊓’) by the axiom: “x ↓ y is the
          greatest lower bound”; i.e., \(z ≤ x ↓ y \quad≡\quad z ≤
          x \,∧\, z ≤ y\).</p>
        </div>
        <p><abbr class="tooltip" title=
        "A story whose events have smooth transitions connecting them.&lt;br&gt;&lt;br&gt;# A proof wherein each step is connected to the next step by an explicit&lt;br&gt;# justification.&lt;br&gt;&lt;br&gt;This is a ‘linear’ proof format; also known as &lt;em&gt;equational style&lt;/em&gt; or &lt;em&gt;calculational&lt;br&gt;proof&lt;/em&gt;. This corresponds to the ‘high-school style’ of writing a sequence of&lt;br&gt;equations, one on each line, along with hints/explanations of how each line was&lt;br&gt;reached from the previous line. ( This is similar to &lt;strong&gt;programming&lt;/strong&gt; which&lt;br&gt;encourages placing &lt;em&gt;comments&lt;/em&gt; to &lt;em&gt;communicate&lt;/em&gt; what's going on to future readers. )&lt;br&gt;&lt;br&gt;The structure of equational proofs allows implicit use of infernece rules&lt;br&gt;Leibniz, Transitvitity &amp; Symmetry &amp; Reflexivity of equality, and&lt;br&gt;Substitution. In contrast, the structure of proof trees is no help in this&lt;br&gt;regard, and so all uses of inference rules must be mentioned explicitly.&lt;br&gt;&lt;br&gt;For comparison with other proof notations see Equational Propositional Logic (http://www.cse.yorku.ca/~logicE/misc/logicE_intro.pdf).&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;We advocate &lt;em&gt;calculational proofs&lt;/em&gt; in which reasoning is goal directed and&lt;br&gt;justified by simple axiomatic laws that can be checked syntactically rather than&lt;br&gt;semantically. ---&lt;em&gt;Program Construction&lt;/em&gt; by Roland Backhouse&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;Calculational proofs introduce notation and recall theorems as needed, thereby&lt;br&gt;making each step of the argument easy to verify and follow. Thus, such arguments&lt;br&gt;are more accessible to readers unfamiliar with the problem domain.&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;The use of a formal approach let us keep track of when our statements are&lt;br&gt;equivalent (“=”) rather than being weakened (“⇒”). That is, the use of English&lt;br&gt;to express the connection between steps is usually presented naturally using “if&lt;br&gt;this, then that” statements ---i.e., implication--- rather than stronger notion&lt;br&gt;of equality.">
        Calculational Proof</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Calculational Proof</h3>
          <p>A story whose events have smooth transitions
          connecting them.</p>
          <p>This is a ‘linear’ proof format; also known as
          <i>equational style</i> or <i>calculational proof</i>.
          This corresponds to the ‘high-school style’ of writing a
          sequence of equations, one on each line, along with
          hints/explanations of how each line was reached from the
          previous line. ( This is similar to <b>programming</b>
          which encourages placing <i>comments</i> to
          <i>communicate</i> what’s going on to future readers.
          )</p>
          <p>The structure of equational proofs allows implicit use
          of infernece rules Leibniz, Transitvitity & Symmetry &
          Reflexivity of equality, and Substitution. In contrast,
          the structure of proof trees is no help in this regard,
          and so all uses of inference rules must be mentioned
          explicitly.</p>
          <p>For comparison with other proof notations see <a href=
          "http://www.cse.yorku.ca/~logicE/misc/logicE_intro.pdf">Equational
          Propositional Logic</a>.</p>
          <hr>
          <p>We advocate <i>calculational proofs</i> in which
          reasoning is goal directed and justified by simple
          axiomatic laws that can be checked syntactically rather
          than semantically. ---<i>Program Construction</i> by
          Roland Backhouse</p>
          <hr>
          <p>Calculational proofs introduce notation and recall
          theorems as needed, thereby making each step of the
          argument easy to verify and follow. Thus, such arguments
          are more accessible to readers unfamiliar with the
          problem domain.</p>
          <hr>
          <p>The use of a formal approach let us keep track of when
          our statements are equivalent (“=”) rather than being
          weakened (“⇒”). That is, the use of English to express
          the connection between steps is usually presented
          naturally using “if this, then that” statements —i.e.,
          implication— rather than stronger notion of equality.</p>
        </div>
      </div>
      <div id="outline-container-Misc" class="outline-3">
        <h3 id="Misc"><span class="section-number-3">1.1.</span>
        Misc&nbsp;&nbsp;&nbsp;<span class="tag"><span class=
        "ignore">ignore</span></span></h3>
        <div class="outline-text-3" id="text-Misc">
          <p><abbr class="tooltip" title=
          "Programming is solving the equation &lt;em&gt;R ⇒[C] G&lt;/em&gt; in the unknown &lt;em&gt;C&lt;/em&gt;; i.e., it is the&lt;br&gt; activity of finding a ‘recipe’ that satisfies a given specification. Sometimes&lt;br&gt; we may write &lt;em&gt;R ⇒[?] G&lt;/em&gt; and solve for ‘?’. Programming is a goal-directed activity: From a specification, a program is found by examining the shape of its postcondition.">
          Programming</abbr></p>
          <div style=
          "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
            <h3>Programming</h3>
            <p>Programming is solving the equation <i>R ⇒[C] G</i>
            in the unknown <i>C</i>; i.e., it is the activity of
            finding a ‘recipe’ that satisfies a given
            specification. Sometimes we may write <i>R ⇒[?] G</i>
            and solve for ‘?’. Programming is a goal-directed
            activity: From a specification, a program is found by
            examining the shape of its postcondition.</p>
          </div>
          <p><abbr class="tooltip" title=
          "A specification is an equation of a certain shape.&lt;br&gt; &lt;em&gt;Programming&lt;/em&gt; is the activity of solving a specification&lt;br&gt; for its unknown. Its unknown is called a &lt;em&gt;program&lt;/em&gt;.&lt;br&gt;&lt;br&gt; See also “Programming”.">
          Specification</abbr></p>
          <div style=
          "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
            <h3>Specification</h3>
            <p>A specification is an equation of a certain shape.
            <i>Programming</i> is the activity of solving a
            specification for its unknown. Its unknown is called a
            <i>program</i>.</p>
            <p>See also “Programming”.</p>
          </div>
          <p><abbr class="tooltip" title=
          "Problems may be formulated and solved using, possibly implicitly, the&lt;br&gt; construction of correct programs:&lt;br&gt;&lt;br&gt;   &lt;em&gt;“for all x satisfying R(x), there is a y such that G(x,y) is true”&lt;/em&gt;&lt;br&gt; ≈ &lt;em&gt;∀ x • R x ⇒ ∃ y • G x y&lt;/em&gt;&lt;br&gt; ≈ &lt;em&gt;R {𝑺} G for some program 𝑺 with inputs x and outputs y&lt;/em&gt;&lt;br&gt;&lt;br&gt; This is known as a &lt;em&gt;constructive proof&lt;/em&gt; since we have an algorithm 𝑺 that actually&lt;br&gt; shows how to find a particular &lt;em&gt;y&lt;/em&gt; to solve the problem, for any given x. In&lt;br&gt; contrast, non-constructive proofs usually involving some form of counting&lt;br&gt; followed by a phrase “there is at least one such &lt;em&gt;y&lt;/em&gt; …”, without actually&lt;br&gt; indicating &lt;em&gt;how&lt;/em&gt; to find it!&lt;br&gt;&lt;br&gt; The &lt;em&gt;“R {𝑺} G”&lt;/em&gt; is known as a ‘Hoare triple’ and it expresses “when begun in a&lt;br&gt; state satisfying &lt;em&gt;R&lt;/em&gt;, program 𝑺 will terminate in a state satisfying &lt;em&gt;G&lt;/em&gt;.”&lt;br&gt;&lt;br&gt; &lt;hr&gt;&lt;br&gt;&lt;br&gt; + Proving ≈ Programming&lt;br&gt; + Logic  ≈ Trees (algebraic data types, 𝒲-types)&lt;br&gt; + Rules  ≈ Constructors&lt;br&gt; + Proof  ≈ An application of constructors&lt;br&gt; + Axiom  ≈ A constructor with no arguments">
          Proving_is_Programming</abbr></p>
          <div style=
          "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
            <h3>Proving_is_Programming</h3>
            <p>Problems may be formulated and solved using,
            possibly implicitly, the construction of correct
            programs:</p>
            <p><i>“for all x satisfying R(x), there is a y such
            that G(x,y) is true”</i> ≈ <i>∀ x • R x ⇒ ∃ y • G x
            y</i> ≈ <i>R {𝑺} G for some program 𝑺 with inputs x and
            outputs y</i></p>
            <p>This is known as a <i>constructive proof</i> since
            we have an algorithm 𝑺 that actually shows how to find
            a particular <i>y</i> to solve the problem, for any
            given x. In contrast, non-constructive proofs usually
            involving some form of counting followed by a phrase
            “there is at least one such <i>y</i> …”, without
            actually indicating <i>how</i> to find it!</p>
            <p>The <i>“R {𝑺} G”</i> is known as a ‘Hoare triple’
            and it expresses “when begun in a state satisfying
            <i>R</i>, program 𝑺 will terminate in a state
            satisfying <i>G</i>.”</p>
            <hr>
            <ul class="org-ul">
              <li>Proving ≈ Programming</li>
              <li>Logic ≈ Trees (algebraic data types,
              𝒲-types)</li>
              <li>Rules ≈ Constructors</li>
              <li>Proof ≈ An application of constructors</li>
              <li>Axiom ≈ A constructor with no arguments</li>
            </ul>
          </div>
          <p><abbr class="tooltip" title=
          "There are two ways to read this phrase.&lt;br&gt;&lt;br&gt; Algorithmic-problem solving is about solving problems that&lt;br&gt; involve the construction of an algorithm for their solution.&lt;br&gt;&lt;br&gt; Algorithmic problem-solving is about problem solving in general,&lt;br&gt; using the principles of correct-by-construction algorithm-design.">
          Algorithmic Problem Solving</abbr></p>
          <div style=
          "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
            <h3>Algorithmic Problem Solving</h3>
            <p>There are two ways to read this phrase.</p>
            <p>Algorithmic-problem solving is about solving
            problems that involve the construction of an algorithm
            for their solution.</p>
            <p>Algorithmic problem-solving is about problem solving
            in general, using the principles of
            correct-by-construction algorithm-design.</p>
          </div>
          <p><abbr class="tooltip" title=
          "Natural transformations are essentially polymorphic functions that make &lt;em&gt;no&lt;/em&gt;&lt;br&gt; choices according to the input type; e.g., =reverse : List τ → List τ= makes no&lt;br&gt; choices depending on the type &lt;code&gt;τ&lt;/code&gt;.">
          Natural Transformation</abbr></p>
          <div style=
          "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
            <h3>Natural Transformation</h3>
            <p>Natural transformations are essentially polymorphic
            functions that make <i>no</i> choices according to the
            input type; e.g., <code>reverse : List τ → List
            τ</code> makes no choices depending on the type
            <code>τ</code>.</p>
          </div>
          <p><abbr class="tooltip" title=
          "A theory of typed composition; e.g., typed monoids.">Category
          Theory</abbr></p>
          <div style=
          "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
            <h3>Category Theory</h3>
            <p>A theory of typed composition; e.g., typed
            monoids.</p>
          </div>
        </div>
      </div>
    </div>
    <div id="outline-container-Properties-of-Operators-Relations"
    class="outline-2">
      <h2 id="Properties-of-Operators-Relations"><span class=
      "section-number-2">2.</span> Properties of Operators</h2>
      <div class="outline-text-2" id=
      "text-Properties-of-Operators-Relations">
        <p><abbr class="tooltip" title=
        "An operation _⊕_ is associative when it satisfies &lt;em&gt;(p ⊕ q) ⊕ r = p ⊕ (q ⊕ r)&lt;/em&gt;.&lt;br&gt;&lt;br&gt;Associativity allows us to be informal and insert or delete pairs of&lt;br&gt;parentheses in sequences of ⊕'s, just as we do with sequences of&lt;br&gt;additions ---e.g., &lt;em&gt;a + b + c + d&lt;/em&gt; is equivalent to &lt;em&gt;a + (b + c) + d&lt;/em&gt;.&lt;br&gt;&lt;br&gt;Hence, we can write &lt;em&gt;p ⊕ q ⊕ r&lt;/em&gt; instead of &lt;em&gt;(p ⊕ q) ⊕ r&lt;/em&gt; or &lt;em&gt;p ⊕ (q ⊕ r)&lt;/em&gt;.&lt;br&gt;&lt;br&gt;When an operation is associative, it is best to avoid “making a choice” of how&lt;br&gt;sequences of ⊕ should be read, by using parentheses ---unless to make things&lt;br&gt;clear or explicit for manipulation.&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;More generally, for any two operations _⊕_ and _⊞_, the “(left to right) mutual&lt;br&gt;associativity of ⊕ and ⊞” is the property &lt;em&gt;(x ⊕ y) ⊞ z = x ⊕ (y ⊞ z)&lt;/em&gt;. It allows&lt;br&gt;us to omit parentheses in mixed sequences of ⊕ and ⊞. For instance, addition and&lt;br&gt;subtraction are (left to right) mutually associative.">
        Associative</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Associative</h3>
          <p>An operation <span class="underline">⊕</span> is
          associative when it satisfies \((p ⊕ q) ⊕ r = p ⊕ (q ⊕
          r)\).</p>
          <p>Associativity allows us to be informal and insert or
          delete pairs of parentheses in sequences of ⊕’s, just as
          we do with sequences of additions —e.g., \(a + b + c +
          d\) is equivalent to \(a + (b + c) + d\).</p>
          <p>Hence, we can write \(p ⊕ q ⊕ r\) instead of \((p ⊕ q)
          ⊕ r\) or \(p ⊕ (q ⊕ r)\).</p>
          <p>When an operation is associative, it is best to avoid
          “making a choice” of how sequences of ⊕ should be read,
          by using parentheses —unless to make things clear or
          explicit for manipulation.</p>
          <hr>
          <p>More generally, for any two operations <span class=
          "underline">⊕</span> and <span class=
          "underline">⊞</span>, the “(left to right) mutual
          associativity of ⊕ and ⊞” is the property \((x ⊕ y) ⊞ z =
          x ⊕ (y ⊞ z)\). It allows us to omit parentheses in mixed
          sequences of ⊕ and ⊞. For instance, addition and
          subtraction are (left to right) mutually associative.</p>
        </div>
        <p><abbr class="tooltip" title=
        "An operation _⊕_ has identity 𝑰 when it satisfies &lt;em&gt;𝑰 ⊕ x = x = x ⊕ 𝑰&lt;/em&gt;.&lt;br&gt;&lt;br&gt;If it satisfies only the first equation, &lt;em&gt;𝑰 ⊕ x = x&lt;/em&gt;, one says&lt;br&gt;that “𝑰 is a left-identity for ⊕”. If it satisfies only the second&lt;br&gt;equation, &lt;em&gt;x ⊕ 𝑰 = x&lt;/em&gt;, one says that “𝑰 is a right-identity for ⊕”.&lt;br&gt;&lt;br&gt;For example, implication only has a left identity, &lt;em&gt;(false ⇒ x) = x&lt;/em&gt;, and&lt;br&gt;subtraction only has a right identity, &lt;em&gt;(x - 0) = x&lt;/em&gt;.&lt;br&gt;&lt;br&gt;An identity implies that occurrences of “⊕ 𝑰” and “𝑰 ⊕” in an expression are&lt;br&gt;redundant. Thus, &lt;em&gt;x ⊕ 𝑰&lt;/em&gt; may be replaced by &lt;em&gt;x&lt;/em&gt; in any expression without&lt;br&gt;changing the value of the expression. Therefore, we usually eliminate such&lt;br&gt;occurrences unless something encourages us to leave them in.">
        Identity</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Identity</h3>
          <p>An operation <span class="underline">⊕</span> has
          identity 𝑰 when it satisfies \(𝑰 ⊕ x = x = x ⊕ 𝑰\).</p>
          <p>If it satisfies only the first equation, \(𝑰 ⊕ x =
          x\), one says that “𝑰 is a left-identity for ⊕”. If it
          satisfies only the second equation, \(x ⊕ 𝑰 = x\), one
          says that “𝑰 is a right-identity for ⊕”.</p>
          <p>For example, implication only has a left identity,
          \((false ⇒ x) = x\), and subtraction only has a right
          identity, \((x - 0) = x\).</p>
          <p>An identity implies that occurrences of “⊕ 𝑰” and “𝑰
          ⊕” in an expression are redundant. Thus, \(x ⊕ 𝑰\) may be
          replaced by \(x\) in any expression without changing the
          value of the expression. Therefore, we usually eliminate
          such occurrences unless something encourages us to leave
          them in.</p>
        </div>
        <p><abbr class="tooltip" title=
        "An operation ⊗ distributes over ⊕ when they satisfy&lt;br&gt;“left-distributivity” &lt;em&gt;x ⊗ (y ⊕ z) = (x ⊗ y) ⊕ (x ⊗ y)&lt;/em&gt;&lt;br&gt;and&lt;br&gt;“right-distributivity” &lt;em&gt;(y ⊕ z) ⊗ x = (y ⊗ x) ⊕ (z ⊗ x)&lt;/em&gt;.&lt;br&gt;&lt;br&gt;When ⊕ = ⊗, one says that the operation is “self-distributive”.&lt;br&gt;&lt;br&gt;Distributivity can be viewed in two ways, much like distributivity of&lt;br&gt;multiplication × over addition +. Replacing the left side by the right side&lt;br&gt;could be called “multiplying out”; replacing the right side by the left side,&lt;br&gt;“factoring”.">
        Distributive</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Distributive</h3>
          <p>An operation ⊗ distributes over ⊕ when they satisfy
          “left-distributivity” \(x ⊗ (y ⊕ z) = (x ⊗ y) ⊕ (x ⊗ y)\)
          and “right-distributivity” \((y ⊕ z) ⊗ x = (y ⊗ x) ⊕ (z ⊗
          x)\).</p>
          <p>When ⊕ = ⊗, one says that the operation is
          “self-distributive”.</p>
          <p>Distributivity can be viewed in two ways, much like
          distributivity of multiplication × over addition +.
          Replacing the left side by the right side could be called
          “multiplying out”; replacing the right side by the left
          side, “factoring”.</p>
        </div>
        <p><abbr class="tooltip" title=
        "An operation _⊕_ is &lt;em&gt;commutative&lt;/em&gt; or &lt;em&gt;symmetric&lt;/em&gt; if it satisfies &lt;em&gt;x ⊕ y = y ⊕ x&lt;/em&gt;.&lt;br&gt;&lt;br&gt;This property indicates (semantically) that the value of an ⊕-expression doesn't&lt;br&gt;depend on the order of its arguments and (syntactically) we may swap their order&lt;br&gt;when manipulating ⊕-expressions.">
        Commutative</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Commutative</h3>
          <p>An operation <span class="underline">⊕</span> is
          <i>commutative</i> or <i>symmetric</i> if it satisfies
          <i>x ⊕ y = y ⊕ x</i>.</p>
          <p>This property indicates (semantically) that the value
          of an ⊕-expression doesn’t depend on the order of its
          arguments and (syntactically) we may swap their order
          when manipulating ⊕-expressions.</p>
        </div>
      </div>
    </div>
    <div id="outline-container-Properties-of-Homogeneous-Relations"
    class="outline-2">
      <h2 id="Properties-of-Homogeneous-Relations"><span class=
      "section-number-2">3.</span> Properties of <i>Homogeneous</i>
      Relations</h2>
      <div class="outline-text-2" id=
      "text-Properties-of-Homogeneous-Relations">
        <p><abbr class="tooltip" title=
        "/Elements are related to themselves/&lt;br&gt;&lt;hr&gt;&lt;br&gt;A relation &lt;EM&gt;R : V → V&lt;/EM&gt; can be visualised as a drawing: A dot for each element&lt;br&gt;&lt;em&gt;x&lt;/em&gt; of &lt;EM&gt;V&lt;/EM&gt;, and a directed line &lt;em&gt;x ⟶ y&lt;/em&gt; between two points exactly when &lt;em&gt;x 〔R〕&lt;br&gt;y&lt;/em&gt;. That is relations are &lt;em&gt;simple graphs&lt;/em&gt;; one refers to the directed lines as&lt;br&gt;&lt;em&gt;edges&lt;/em&gt; and the dots as &lt;em&gt;nodes&lt;/em&gt;.&lt;br&gt;&lt;br&gt;As a simple graph, reflexivity means &lt;em&gt;there is loop “ ⟳ ” at each node.&lt;/em&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;  &lt;em&gt;R&lt;/em&gt; is reflexive exactly when &lt;em&gt;everything is related to itself&lt;/em&gt;.&lt;br&gt;≡ &lt;em&gt;∀ x • x 〔R〕 x&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;Id ⊆ R&lt;/em&gt;&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.">
        Reflexive</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Reflexive</h3>
          <p><i>Elements are related to themselves</i></p>
          <hr>
          <p>A relation \(R : V → V\) can be visualised as a
          drawing: A dot for each element \(x\) of \(V\), and a
          directed line \(x ⟶ y\) between two points exactly when
          \(x 〔R〕 y\). That is relations are <i>simple graphs</i>;
          one refers to the directed lines as <i>edges</i> and the
          dots as <i>nodes</i>.</p>
          <p>As a simple graph, reflexivity means <i>there is loop
          “ ⟳ ” at each node.</i></p>
          <hr>
          <p><i>R</i> is reflexive exactly when <i>everything is
          related to itself</i>. ≡ <i>∀ x • x 〔R〕 x</i> ≡ \(Id ⊆
          R\)</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
        </div>
        <p><abbr class="tooltip" title=
        "A relation _⊑_ is &lt;em&gt;transitive&lt;/em&gt; when it satisfies &lt;em&gt;a ⊑ b &nbsp;∧&nbsp; b ⊑ c &nbsp;⇒&nbsp; a ⊑ c&lt;/em&gt;;&lt;br&gt;i.e., &lt;em&gt;a ⊑ b ⊑ c &nbsp;⇒&nbsp;a ⊑ c&lt;/em&gt; ---that is, “we can chain ⊑” so that from a proof of &lt;em&gt;a&lt;br&gt;⊑ b ⊑ c&lt;/em&gt; we can get from the first to the final part and so have a proof of&lt;br&gt;&lt;em&gt;a ⊑ c&lt;/em&gt;.&lt;br&gt;&lt;br&gt;Loosely put, whenever &lt;em&gt;a&lt;/em&gt; and &lt;em&gt;c&lt;/em&gt; have a common relative then they are themselves&lt;br&gt;related.&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;A relation &lt;EM&gt;R : V → V&lt;/EM&gt; can be visualised as a drawing: A dot for each element&lt;br&gt;&lt;em&gt;x&lt;/em&gt; of &lt;EM&gt;V&lt;/EM&gt;, and a directed line &lt;em&gt;x ⟶ y&lt;/em&gt; between two points exactly when &lt;em&gt;x 〔R〕&lt;br&gt;y&lt;/em&gt;. That is relations are &lt;em&gt;simple graphs&lt;/em&gt;; one refers to the directed lines as&lt;br&gt;&lt;em&gt;edges&lt;/em&gt; and the dots as &lt;em&gt;nodes&lt;/em&gt;.&lt;br&gt;&lt;br&gt;As a simple graph, transitivity means &lt;em&gt;paths can always be shortened (but&lt;br&gt;nonempty).&lt;/em&gt;&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;By the shunting rule, transitivity can be read as a &lt;strong&gt;‘monotonicity’&lt;/strong&gt; property for&lt;br&gt;the operation that turns a value &lt;em&gt;x&lt;/em&gt; into the proposition &lt;em&gt;a ⊑ x&lt;/em&gt;; this maps ordered&lt;br&gt;relationships &lt;em&gt;b ⊑ c&lt;/em&gt; to ordered propositions &lt;em&gt;a ⊑ b ⇒ a ⊑ c&lt;/em&gt;.&lt;br&gt;&lt;br&gt;Likewise, transitivity can be read as an ‘&lt;strong&gt;antitonicity&lt;/strong&gt;’ property for the&lt;br&gt;operation mapping a value &lt;em&gt;x&lt;/em&gt; to the proposition &lt;em&gt;x ⊑ c&lt;/em&gt;; this maps ordered&lt;br&gt;relationships &lt;em&gt;a ⊑ b&lt;/em&gt; to ordered propositions &lt;em&gt;b ⊑ c ⇒ a ⊑ c&lt;/em&gt;.&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;  Relation &lt;em&gt;R&lt;/em&gt; is transitive&lt;br&gt;≡ &lt;em&gt;Things related to things that are related, are themselves related.&lt;/em&gt;&lt;br&gt;≡ Whenever &lt;em&gt;x&lt;/em&gt; is related to &lt;em&gt;y&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt; is related to &lt;em&gt;z&lt;/em&gt;, then also &lt;em&gt;x&lt;/em&gt; will&lt;br&gt;  be related to &lt;em&gt;z&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∀ x, y, z • x 〔 R 〕 y 〔R 〕 z ⇒ x 〔R〕 z&lt;/em&gt;&lt;br&gt;≡ &lt;EM&gt;R ⨾ R ⊆ R&lt;/EM&gt;&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.&lt;br&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;A transitive relation is irreflexive precisely when it is asymmetric.">
        Transitive</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFCC;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Transitive</h3>
          <p>A relation <span class="underline">⊑</span> is
          <i>transitive</i> when it satisfies <i>a ⊑ b
          &nbsp;∧&nbsp; b ⊑ c &nbsp;⇒&nbsp; a ⊑ c</i>; i.e., <i>a ⊑
          b ⊑ c &nbsp;⇒&nbsp;a ⊑ c</i> —that is, “we can chain ⊑”
          so that from a proof of <i>a ⊑ b ⊑ c</i> we can get from
          the first to the final part and so have a proof of <i>a ⊑
          c</i>.</p>
          <p>Loosely put, whenever <i>a</i> and <i>c</i> have a
          common relative then they are themselves related.</p>
          <hr>
          <p>A relation \(R : V → V\) can be visualised as a
          drawing: A dot for each element \(x\) of \(V\), and a
          directed line \(x ⟶ y\) between two points exactly when
          \(x 〔R〕 y\). That is relations are <i>simple graphs</i>;
          one refers to the directed lines as <i>edges</i> and the
          dots as <i>nodes</i>.</p>
          <p>As a simple graph, transitivity means <i>paths can
          always be shortened (but nonempty).</i></p>
          <hr>
          <p>By the shunting rule, transitivity can be read as a
          <b>‘monotonicity’</b> property for the operation that
          turns a value <i>x</i> into the proposition <i>a ⊑ x</i>;
          this maps ordered relationships <i>b ⊑ c</i> to ordered
          propositions <i>a ⊑ b ⇒ a ⊑ c</i>.</p>
          <p>Likewise, transitivity can be read as an
          ‘*antitonicity*’ property for the operation mapping a
          value <i>x</i> to the proposition <i>x ⊑ c</i>; this maps
          ordered relationships <i>a ⊑ b</i> to ordered
          propositions <i>b ⊑ c ⇒ a ⊑ c</i>.</p>
          <hr>
          <p>Relation <i>R</i> is transitive ≡ <i>Things related to
          things that are related, are themselves related.</i> ≡
          Whenever <i>x</i> is related to <i>y</i> and <i>y</i> is
          related to <i>z</i>, then also <i>x</i> will be related
          to <i>z</i> ≡ <i>∀ x, y, z • x 〔 R 〕 y 〔R 〕 z ⇒ x 〔R〕
          z</i> ≡ \(R ⨾ R ⊆ R\)</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
          <hr>
          <p>A transitive relation is irreflexive precisely when it
          is asymmetric.</p>
        </div>
        <p><abbr class="tooltip" title=
        "/The relationship is mutual; if one thing is related to the other, then the other&lt;br&gt;is also related to the first.&lt;em&gt;&lt;br&gt;&lt;br&gt;  &lt;EM&gt;R&lt;/EM&gt; is symmetric&lt;br&gt;≡ If &lt;/em&gt;x/ is related to &lt;em&gt;y&lt;/em&gt;, then &lt;em&gt;y&lt;/em&gt; is also related to &lt;em&gt;x&lt;/em&gt;.&lt;br&gt;≡ &lt;em&gt;∀ x, y • x 〔R〕 y ⇒ y 〔 R〕 x&lt;/em&gt;&lt;br&gt;≡ &lt;EM&gt;R ˘ ⊆ R&lt;/EM&gt;&lt;br&gt;≡ &lt;EM&gt;R ∩ R˘ ⊆ R&lt;/EM&gt;&lt;br&gt;≡ &lt;EM&gt;R ˘ = R&lt;/EM&gt;&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;A relation &lt;EM&gt;R : V → V&lt;/EM&gt; can be visualised as a drawing: A dot for each element&lt;br&gt;&lt;em&gt;x&lt;/em&gt; of &lt;EM&gt;V&lt;/EM&gt;, and a directed line &lt;em&gt;x ⟶ y&lt;/em&gt; between two points exactly when &lt;em&gt;x 〔R〕&lt;br&gt;y&lt;/em&gt;. That is relations are &lt;em&gt;simple graphs&lt;/em&gt;; one refers to the directed lines as&lt;br&gt;&lt;em&gt;edges&lt;/em&gt; and the dots as &lt;em&gt;nodes&lt;/em&gt;.&lt;br&gt;&lt;br&gt;As a simple graph, symmetry means the graphs is &lt;em&gt;undirected&lt;/em&gt;.&lt;br&gt;&lt;br&gt;That is, as graphs, symmetric relations contains either exactly two arrows ---in&lt;br&gt;opposite directions--- between any two elements or none at all. As such, for&lt;br&gt;clarity, one prefers “squeezing any two arrows in opposite directions” into one&lt;br&gt;‘undirected’ line and so obtains &lt;strong&gt;undirected graphs&lt;/strong&gt;.&lt;br&gt;- Undirected edges represent pairs of arrows pointing in opposite directions.&lt;br&gt;&lt;br&gt; Coreflexives are symmetric: &lt;em&gt;R ⊆ Id ⇒ R ˘ = R&lt;/em&gt;.&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;Interestingly, every homogeneous relation &lt;em&gt;R&lt;/em&gt; may be &lt;em&gt;partitioned&lt;/em&gt; into an&lt;br&gt;asymmetric part &lt;EM&gt;A = R ∩ ∼R˘&lt;/EM&gt; and a symmetric part &lt;EM&gt;S = R ∩ R˘&lt;/EM&gt;&lt;br&gt;---i.e., &lt;EM&gt;R = A ∪ S&lt;/EM&gt; and &lt;EM&gt;A ∩ S = ⊥&lt;/EM&gt; where ⊥ is the empty relation.">
        Symmetric</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Symmetric</h3>
          <p><i>The relationship is mutual; if one thing is related
          to the other, then the other is also related to the
          first.</i></p>
          <p>\(R\) is symmetric ≡ If <i>x</i> is related to
          <i>y</i>, then <i>y</i> is also related to <i>x</i>. ≡
          <i>∀ x, y • x 〔R〕 y ⇒ y 〔 R〕 x</i> ≡ \(R ˘ ⊆ R\) ≡ \(R ∩
          R˘ ⊆ R\) ≡ \(R ˘ = R\)</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
          <hr>
          <p>A relation \(R : V → V\) can be visualised as a
          drawing: A dot for each element \(x\) of \(V\), and a
          directed line \(x ⟶ y\) between two points exactly when
          \(x 〔R〕 y\). That is relations are <i>simple graphs</i>;
          one refers to the directed lines as <i>edges</i> and the
          dots as <i>nodes</i>.</p>
          <p>As a simple graph, symmetry means the graphs is
          <i>undirected</i>.</p>
          <p>That is, as graphs, symmetric relations contains
          either exactly two arrows —in opposite directions—
          between any two elements or none at all. As such, for
          clarity, one prefers “squeezing any two arrows in
          opposite directions” into one ‘undirected’ line and so
          obtains <b>undirected graphs</b>.</p>
          <ul class="org-ul">
            <li>
              <p>Undirected edges represent pairs of arrows
              pointing in opposite directions.</p>
              <p>Coreflexives are symmetric: \(R ⊆ Id ⇒ R ˘ =
              R\).</p>
            </li>
          </ul>
          <hr>
          <p>Interestingly, every homogeneous relation <i>R</i> may
          be <i>partitioned</i> into an asymmetric part \(A = R ∩
          ∼R˘\) and a symmetric part \(S = R ∩ R˘\) —i.e., \(R = A
          ∪ S\) and \(A ∩ S = ⊥\) where ⊥ is the empty
          relation.</p>
        </div>
        <p><abbr class="tooltip" title=
        "/Different elements cannot be mutually related; i.e.,&lt;br&gt;Mutually related items are necessarily indistinguishable.&lt;em&gt;&lt;br&gt;&lt;br&gt;Such relations allow us to prove equality between two elements;&lt;br&gt;we have only to show that the relationship holds in both directions.&lt;br&gt; * E.g, one often shows two sets are equal by using the antisymmetry of ‘⊆’.&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;A relation &lt;EM&gt;R : V → V&lt;/EM&gt; can be visualised as a drawing: A dot for each element&lt;br&gt;&lt;em&gt;x&lt;/em&gt; of &lt;EM&gt;V&lt;/EM&gt;, and a directed line &lt;em&gt;x ⟶ y&lt;/em&gt; between two points exactly when &lt;em&gt;x 〔R〕&lt;br&gt;y&lt;/em&gt;. That is relations are &lt;/em&gt;simple graphs/; one refers to the directed lines as&lt;br&gt;&lt;em&gt;edges&lt;/em&gt; and the dots as &lt;em&gt;nodes&lt;/em&gt;.&lt;br&gt;&lt;br&gt;As a simple graph, antisymmetry means &lt;em&gt;Mutually related nodes are necessarily self-loops&lt;/em&gt;.&lt;br&gt;&lt;hr&gt;&lt;br&gt;  &lt;EM&gt;R&lt;/EM&gt; is antisymmetric&lt;br&gt;≡ &lt;em&gt;∀ x, y • x 〔R〕 y ∧ y 〔 R〕 x ⇒ x = y&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∀ x, y • x ≠ y ⇒ ¬ (x 〔R〕 y ∧ y 〔 R〕 x)&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∀ x, y • x ≠ y ⇒ x 〔R̸〕 y ∨ y 〔 R̸〕 x&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;R ∩ R ˘ ⊆ Id&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;R ˘ ⊆ ∼ R ∪ Id&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;R ╳ R = Id&lt;/em&gt; ---‘╳’ is symmetric quotient&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.&lt;br&gt;&lt;br&gt;( As a simple graph, an antisymmetric relation has &lt;em&gt;at most&lt;/em&gt; one arrow between&lt;br&gt;any two different nodes. )">
        Antisymmetric</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Antisymmetric</h3>
          <p><i>Different elements cannot be mutually related;
          i.e., Mutually related items are necessarily
          indistinguishable.</i></p>
          <p>Such relations allow us to prove equality between two
          elements; we have only to show that the relationship
          holds in both directions.</p>
          <ul class="org-ul">
            <li>E.g, one often shows two sets are equal by using
            the antisymmetry of ‘⊆’.</li>
          </ul>
          <hr>
          <p>A relation \(R : V → V\) can be visualised as a
          drawing: A dot for each element \(x\) of \(V\), and a
          directed line \(x ⟶ y\) between two points exactly when
          \(x 〔R〕 y\). That is relations are <i>simple graphs</i>;
          one refers to the directed lines as <i>edges</i> and the
          dots as <i>nodes</i>.</p>
          <p>As a simple graph, antisymmetry means <i>Mutually
          related nodes are necessarily self-loops</i>.</p>
          <hr>
          <p>\(R\) is antisymmetric ≡ <i>∀ x, y • x 〔R〕 y ∧ y 〔 R〕
          x ⇒ x = y</i> ≡ <i>∀ x, y • x ≠ y ⇒ ¬ (x 〔R〕 y ∧ y 〔 R〕
          x)</i> ≡ <i>∀ x, y • x ≠ y ⇒ x 〔R̸〕 y ∨ y 〔 R̸〕 x</i> ≡
          \(R ∩ R ˘ ⊆ Id\) ≡ \(R ˘ ⊆ ∼ R ∪ Id\) ≡ <i>R ╳ R = Id</i>
          —‘╳’ is symmetric quotient</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
          <p>( As a simple graph, an antisymmetric relation has
          <i>at most</i> one arrow between any two different nodes.
          )</p>
        </div>
        <p><abbr class="tooltip" title=
        "/The relationship is mutually exclusive.&lt;em&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;A relation &lt;EM&gt;R : V → V&lt;/EM&gt; can be visualised as a drawing: A dot for each element&lt;br&gt;&lt;em&gt;x&lt;/em&gt; of &lt;EM&gt;V&lt;/EM&gt;, and a directed line &lt;em&gt;x ⟶ y&lt;/em&gt; between two points exactly when &lt;em&gt;x 〔R〕&lt;br&gt;y&lt;/em&gt;. That is relations are &lt;/em&gt;simple graphs/; one refers to the directed lines as&lt;br&gt;&lt;em&gt;edges&lt;/em&gt; and the dots as &lt;em&gt;nodes&lt;/em&gt;.&lt;br&gt;&lt;br&gt;As a simple graph, asymmetric means: &lt;em&gt;There's at most 1 edge (regardless of&lt;br&gt;direction) relating any 2 nodes&lt;/em&gt;.&lt;br&gt;&lt;hr&gt;&lt;br&gt;  &lt;EM&gt;R&lt;/EM&gt; is asymmetric&lt;br&gt;≡ &lt;em&gt;∀ x, y • x 〔R〕 y ⇒ ¬ y 〔R〕 x&lt;/em&gt;&lt;br&gt;≡ &lt;EM&gt;R ∩ R ˘ ⊆ ⊥&lt;/EM&gt;&lt;br&gt;≡ &lt;EM&gt;R ˘ ⊆ ∼ R&lt;/EM&gt;&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.&lt;br&gt;&lt;br&gt;Asymmetrics are irreflexive ---just pick &lt;em&gt;x = y&lt;/em&gt; in the above ∀-formulation ;-)&lt;br&gt;&lt;hr&gt;&lt;br&gt;&lt;br&gt;Interestingly, every homogeneous relation &lt;em&gt;R&lt;/em&gt; may be &lt;em&gt;partitioned&lt;/em&gt; into an&lt;br&gt;asymmetric part &lt;EM&gt;A = R ∩ ∼R˘&lt;/EM&gt; and a symmetric part &lt;EM&gt;S = R ∩ R˘&lt;/EM&gt;&lt;br&gt;---i.e., &lt;EM&gt;R = A ∪ S&lt;/EM&gt; and &lt;EM&gt;A ∩ S = ⊥&lt;/EM&gt; where ⊥ is the empty relation.">
        Asymmetric</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Asymmetric</h3>
          <p><i>The relationship is mutually exclusive.</i></p>
          <hr>
          <p>A relation \(R : V → V\) can be visualised as a
          drawing: A dot for each element \(x\) of \(V\), and a
          directed line \(x ⟶ y\) between two points exactly when
          \(x 〔R〕 y\). That is relations are <i>simple graphs</i>;
          one refers to the directed lines as <i>edges</i> and the
          dots as <i>nodes</i>.</p>
          <p>As a simple graph, asymmetric means: <i>There’s at
          most 1 edge (regardless of direction) relating any 2
          nodes</i>.</p>
          <hr>
          <p>\(R\) is asymmetric ≡ <i>∀ x, y • x 〔R〕 y ⇒ ¬ y 〔R〕
          x</i> ≡ \(R ∩ R ˘ ⊆ ⊥\) ≡ \(R ˘ ⊆ ∼ R\)</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
          <p>Asymmetrics are irreflexive —just pick <i>x = y</i> in
          the above ∀-formulation ;-)</p>
          <hr>
          <p>Interestingly, every homogeneous relation <i>R</i> may
          be <i>partitioned</i> into an asymmetric part \(A = R ∩
          ∼R˘\) and a symmetric part \(S = R ∩ R˘\) —i.e., \(R = A
          ∪ S\) and \(A ∩ S = ⊥\) where ⊥ is the empty
          relation.</p>
        </div>
        <p><abbr class="tooltip" title=
        "A &lt;em&gt;preorder&lt;/em&gt; models the notion of ‘inclusion’ or ‘at most’ or ‘before’ or&lt;br&gt;‘predecessor of’; and so requires: &lt;em&gt;Everything is included in itself and&lt;br&gt;inclusion is transitive.&lt;/em&gt;&lt;br&gt;&lt;br&gt; &lt;EM&gt;R&lt;/EM&gt; is a preorder&lt;br&gt;≡ &lt;EM&gt;R&lt;/EM&gt; is transitive and reflexive&lt;br&gt;≡ &lt;em&gt;R ⨾ R ⊆ R  ∧  Id ⊆ R&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;R ⨾ R = R  ∧  Id ⊆ R&lt;/em&gt;&lt;br&gt;≡ &lt;EM&gt;R ╱ R = R&lt;/EM&gt; ---“indirect inclusion from above”&lt;br&gt;≡ &lt;EM&gt;R ╲ R = R&lt;/EM&gt; ---“indirect inclusion from below”&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.&lt;br&gt;&lt;br&gt;If it is additionally &lt;em&gt;antisymmetric&lt;/em&gt;, one says we have an &lt;strong&gt;order&lt;/strong&gt;.&lt;br&gt;- The relation &lt;EM&gt;R ∩ R˘&lt;/EM&gt; is the greatest equivalence contained in a preorder &lt;EM&gt;R&lt;/EM&gt;.&lt;br&gt;&lt;br&gt; Indeed, it's clearly symmetric and reflexive, and transitive since ‘⨾’&lt;br&gt; sub-distributes over ‘∩’ and &lt;em&gt;R&lt;/em&gt; and &lt;em&gt;R˘&lt;/em&gt; are transitive. Then, for any&lt;br&gt; equivalence &lt;em&gt;Ξ ⊆ R&lt;/em&gt;, we have &lt;em&gt;Ξ = Ξ ˘ ⊆ R ˘&lt;/em&gt; and so &lt;em&gt;Ξ ⊆ R ∩ R˘&lt;/em&gt;.&lt;br&gt;&lt;br&gt;Instead of reflexivity, if we have irreflexivity we get &lt;strong&gt;strict order&lt;/strong&gt;:&lt;br&gt; &lt;EM&gt;R&lt;/EM&gt; is a strict order&lt;br&gt;≡ &lt;EM&gt;R&lt;/EM&gt; is transitive and irreflexive&lt;br&gt;≡ &lt;em&gt;R ⨾ R ⊆ R ⊆ ∼Id&lt;/em&gt;&lt;br&gt;≡ &lt;EM&gt;R ⨾ R ⊆ R  ∧  R˘ ⊆ ∼ R&lt;/EM&gt;&lt;br&gt;≡ &lt;EM&gt;R ⨾ R ⊆ R  ∧  R ∩ R˘ ⊆ ⊥&lt;/EM&gt;&lt;br&gt;≡ &lt;EM&gt;R&lt;/EM&gt; is transitive and asymmetric&lt;br&gt;&lt;br&gt;( &lt;em&gt;Warning!&lt;/em&gt; A “strict order” is not an order that is somehow strict. )&lt;br&gt;&lt;br&gt;Orders and strict orders come in pairs: Every order &lt;EM&gt;R&lt;/EM&gt; induces a strict order&lt;br&gt;&lt;em&gt;R ∩ ∼Id&lt;/em&gt;; conversely, every strict order &lt;EM&gt;R&lt;/EM&gt; gives rise to an order &lt;em&gt;R ∪&lt;br&gt;Id&lt;/em&gt;. As such, it is customary to denote order relations by symbols such as ≤,&lt;br&gt;⊆. ≼, ⊑ and their associated strict orders by related symbols &lt;, ⊂, ≺, ⊏,&lt;br&gt;respectively, with *lack the horizontal line ‘─’ below the symbol to indicate&lt;br&gt;irreflexivity ---i.e., the line is a suggestive reminder of equality.&lt;br&gt;&lt;br&gt;When letters are used to denote orders, one may see &lt;em&gt;E&lt;/em&gt; for an order since it is&lt;br&gt;reminiscent of ≤ and ⊆, and may see &lt;em&gt;C&lt;/em&gt; for a strict order since it is reminiscent&lt;br&gt;of &lt; and ⊂.&lt;br&gt;&lt;br&gt;Using ‘≤’ for &lt;em&gt;an arbitrary order&lt;/em&gt; is not ideal since readers may confuse it with&lt;br&gt;the familiar &lt;em&gt;linear&lt;/em&gt; orders for numbers.">
        Preorder</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Preorder</h3>
          <p>A <i>preorder</i> models the notion of ‘inclusion’ or
          ‘at most’ or ‘before’ or ‘predecessor of’; and so
          requires: <i>Everything is included in itself and
          inclusion is transitive.</i></p>
          <p>\(R\) is a preorder ≡ \(R\) is transitive and
          reflexive ≡ \(R ⨾ R ⊆ R \;∧\; Id ⊆ R\) ≡ \(R ⨾ R = R
          \;∧\; Id ⊆ R\) ≡ \(R ╱ R = R\) —“indirect inclusion from
          above” ≡ \(R ╲ R = R\) —“indirect inclusion from
          below”</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
          <p>If it is additionally <i>antisymmetric</i>, one says
          we have an <b>order</b>.</p>
          <ul class="org-ul">
            <li>
              <p>The relation \(R ∩ R˘\) is the greatest
              equivalence contained in a preorder \(R\).</p>
              <p>Indeed, it’s clearly symmetric and reflexive, and
              transitive since ‘⨾’ sub-distributes over ‘∩’ and
              <i>R</i> and <i>R˘</i> are transitive. Then, for any
              equivalence <i>Ξ ⊆ R</i>, we have <i>Ξ = Ξ ˘ ⊆ R
              ˘</i> and so <i>Ξ ⊆ R ∩ R˘</i>.</p>
            </li>
          </ul>
          <p>Instead of reflexivity, if we have irreflexivity we
          get <b>strict order</b>: \(R\) is a strict order ≡ \(R\)
          is transitive and irreflexive ≡ \(R ⨾ R ⊆ R ⊆ ∼Id\) ≡ \(R
          ⨾ R ⊆ R \;∧\; R˘ ⊆ ∼ R\) ≡ \(R ⨾ R ⊆ R \;∧\; R ∩ R˘ ⊆ ⊥\)
          ≡ \(R\) is transitive and asymmetric</p>
          <p>( <i>Warning!</i> A “strict order” is not an order
          that is somehow strict. )</p>
          <p>Orders and strict orders come in pairs: Every order
          \(R\) induces a strict order \(R ∩ ∼Id\); conversely,
          every strict order \(R\) gives rise to an order \(R ∪
          Id\). As such, it is customary to denote order relations
          by symbols such as ≤, ⊆. ≼, ⊑ and their associated strict
          orders by related symbols &lt;, ⊂, ≺, ⊏, respectively,
          with *lack the horizontal line ‘─’ below the symbol to
          indicate irreflexivity —i.e., the line is a suggestive
          reminder of equality.</p>
          <p>When letters are used to denote orders, one may see
          <i>E</i> for an order since it is reminiscent of ≤ and ⊆,
          and may see <i>C</i> for a strict order since it is
          reminiscent of &lt; and ⊂.</p>
          <p>Using ‘≤’ for <i>an arbitrary order</i> is not ideal
          since readers may confuse it with the familiar
          <i>linear</i> orders for numbers.</p>
        </div>
        <p><abbr class="tooltip" title=
        "An &lt;em&gt;equivalence&lt;/em&gt; models the notion of ‘similarity’; &lt;em&gt;Everything is similar to&lt;br&gt;itself, being similar is a mutual relationship, and it is transitive&lt;/em&gt;.&lt;br&gt;&lt;br&gt;  &lt;EM&gt;R&lt;/EM&gt; is an equivalence&lt;br&gt;≡ &lt;EM&gt;R&lt;/EM&gt; is a symmetric preorder&lt;br&gt;≡ &lt;EM&gt;R&lt;/EM&gt; is transitive and reflexive and symmetric&lt;br&gt;≡ &lt;em&gt;R ⨾ R ⊆ R  ∧  Id ⊆ R ⊆ R˘&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;R ⨾ R = R = R˘  ∧  Id ⊆ R&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;R ⨾ R ˘ ⊆ R  ∧  Id ⊆ R&lt;/em&gt;&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.&lt;br&gt;&lt;hr&gt;&lt;br&gt;For example, “2 + 3” and “5” are clearly &lt;strong&gt;not the same&lt;/strong&gt;”: The first is a string&lt;br&gt;of 3 symbols, whereas the latter is a string of a single symbol. However, they&lt;br&gt;are &lt;strong&gt;equivalent&lt;/strong&gt; when we evaluate them and so we want to pretend they are the&lt;br&gt;same, not by using equality, but by using an equivalence relation. ( This&lt;br&gt;equivalence relation is obtained using transitive closure as &lt;em&gt;(R ⨾ R)^*&lt;/em&gt; where&lt;br&gt;&lt;EM&gt;R&lt;/EM&gt; is the evaluation, reduction relation. )&lt;br&gt;&lt;br&gt;In general, “sharing the same feature 𝒇” is an equivalence relation.&lt;br&gt;That is, if &lt;em&gt;f : A → B&lt;/em&gt; is a function, then ∼ is an equivalence relation&lt;br&gt;defined by &lt;em&gt;a₁ ∼ a₂  ≡  f(a₁)  =  f(a₂)&lt;/em&gt;.&lt;br&gt;&lt;hr&gt;&lt;br&gt;Characterising Equivalences with “Indirect Equivalence”:&lt;br&gt;Ξ is an equivalence ≡ &lt;em&gt;∀ x, y • x 〔Ξ〕 y  ≡  (∀ z • x 〔Ξ〕 z  ≡  y 〔Ξ〕 z)&lt;/em&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;Equivalence relations coincide with partitions.">
        Equivalence</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Equivalence</h3>
          <p>An <i>equivalence</i> models the notion of
          ‘similarity’; <i>Everything is similar to itself, being
          similar is a mutual relationship, and it is
          transitive</i>.</p>
          <p>\(R\) is an equivalence ≡ \(R\) is a symmetric
          preorder ≡ \(R\) is transitive and reflexive and
          symmetric ≡ \(R ⨾ R ⊆ R \;∧\; Id ⊆ R ⊆ R˘\) ≡ \(R ⨾ R = R
          = R˘ \;∧\; Id ⊆ R\) ≡ \(R ⨾ R ˘ ⊆ R \;∧\; Id ⊆ R\)</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
          <hr>
          <p>For example, “2 + 3” and “5” are clearly <b>not the
          same*”: The first is a string of 3 symbols, whereas the
          latter is a string of a single symbol. However, they are
          *equivalent</b> when we evaluate them and so we want to
          pretend they are the same, not by using equality, but by
          using an equivalence relation. ( This equivalence
          relation is obtained using transitive closure as \((R ⨾
          R)^*\) where \(R\) is the evaluation, reduction relation.
          )</p>
          <p>In general, “sharing the same feature 𝒇” is an
          equivalence relation. That is, if \(f : A → B\) is a
          function, then ∼ is an equivalence relation defined by
          \(a₁ ∼ a₂ \quad≡\quad f(a₁) \;=\; f(a₂)\).</p>
          <hr>
          <p>Characterising Equivalences with “Indirect
          Equivalence”: Ξ is an equivalence ≡ \(∀ x, y • x 〔Ξ〕 y
          \quad≡\quad (∀ z • x 〔Ξ〕 z \;≡\; y 〔Ξ〕 z)\)</p>
          <hr>
          <p>Equivalence relations coincide with partitions.</p>
        </div>
        <p><abbr class="tooltip" title=
        "/Any two (possibly identical) members are related/; (the associated&lt;br&gt;graph can be drawn &lt;em&gt;similar&lt;/em&gt; to a line; i.e., the nodes can be arranged in a&lt;br&gt;sequence).&lt;br&gt;&lt;br&gt;( In graph terminology, linear is also referred to as &lt;em&gt;strongly complete&lt;/em&gt;. )&lt;br&gt;&lt;br&gt;( Sometimes a linear &lt;em&gt;order&lt;/em&gt; is called a &lt;em&gt;complete order&lt;/em&gt;. )&lt;br&gt;&lt;br&gt;  &lt;EM&gt;R&lt;/EM&gt; is linear&lt;br&gt;≡ &lt;em&gt;∀ x, y • x 〔R〕 y ∨ y 〔R〕 x&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;⊤ ⊆ R ∪ R ˘&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∼ R ⊆ R ˘&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∼ R&lt;/em&gt; is asymmetric&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.&lt;br&gt;&lt;hr&gt;&lt;br&gt;A linear &lt;em&gt;order&lt;/em&gt; corresponds to a full upper triangular matrix, &lt;em&gt;after&lt;/em&gt; suitably&lt;br&gt;arranging rows and columns. A linear (pre)-&lt;em&gt;order&lt;/em&gt; has no (distinct) incomparable&lt;br&gt;elements.&lt;br&gt;&lt;br&gt;Any linear ordering &lt;em&gt;E&lt;/em&gt;, with associated strict order &lt;em&gt;C&lt;/em&gt;, satisfies &lt;EM&gt;C˘ = ∼E&lt;/EM&gt;;&lt;br&gt;i.e., any linear order ‘⊑’ satisfies &lt;em&gt;∀ x, y •  ¬ (x ⊑ y)  ≡  y ⊏ x&lt;/em&gt;.&lt;br&gt;&lt;br&gt;Likewise, for liner order, we have &lt;em&gt;transitivity E⨾C⨾E = C&lt;/em&gt; and &lt;em&gt;weakening C ⊆ E&lt;/em&gt;;&lt;br&gt;i.e., &lt;em&gt;a ⊑ b ⊏ c ⊑ d  ⇒  a ⊏ d    and    x ⊏ y  ⇒  x ⊑ y&lt;/em&gt;.&lt;br&gt;&lt;br&gt;Every order &lt;em&gt;E&lt;/em&gt; can be extended to a linear order &lt;em&gt;E′&lt;/em&gt;; i.e., &lt;em&gt;E ⊆ E′&lt;/em&gt;. For the&lt;br&gt;finite case this is known as &lt;em&gt;topological sort&lt;/em&gt;, and for the infinite case this is&lt;br&gt;known as the &lt;em&gt;Szpilrajn extension&lt;/em&gt;.&lt;br&gt;&lt;br&gt;- For the finite case, the &lt;em&gt;idea&lt;/em&gt; is as follows: If &lt;em&gt;E&lt;/em&gt; is not linear, then there&lt;br&gt; are two incomparable elements &lt;em&gt;x, y&lt;/em&gt; (i.e., outside &lt;em&gt;E ∪ E˘&lt;/em&gt;), so we may define&lt;br&gt; &lt;em&gt;an&lt;/em&gt; ordering &lt;em&gt;E₁ ≔ E ∪ {(x, y)}&lt;/em&gt;. We iterate this process and &lt;em&gt;Eₙ&lt;/em&gt; will&lt;br&gt; eventually become linear.&lt;br&gt;&lt;br&gt; This process maintains “the order &lt;em&gt;E&lt;/em&gt;, less the incomparable elements, is&lt;br&gt; linear” invariant throughout. Since each step reduces the number of&lt;br&gt; incomparable elements, it must terminate, and the invariant then ensures the&lt;br&gt; resulting order is linear. (•̀ᴗ•́)و">
        Linear</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Linear</h3>
          <p><i>Any two (possibly identical) members are
          related</i>; (the associated graph can be drawn
          <i>similar</i> to a line; i.e., the nodes can be arranged
          in a sequence).</p>
          <p>( In graph terminology, linear is also referred to as
          <i>strongly complete</i>. )</p>
          <p>( Sometimes a linear <i>order</i> is called a
          <i>complete order</i>. )</p>
          <p>\(R\) is linear ≡ <i>∀ x, y • x 〔R〕 y ∨ y 〔R〕 x</i> ≡
          \(⊤ ⊆ R ∪ R ˘\) ≡ \(∼ R ⊆ R ˘\) ≡ \(∼ R\) is
          asymmetric</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
          <hr>
          <p>A linear <i>order</i> corresponds to a full upper
          triangular matrix, <i>after</i> suitably arranging rows
          and columns. A linear (pre)-<i>order</i> has no
          (distinct) incomparable elements.</p>
          <p>Any linear ordering <i>E</i>, with associated strict
          order <i>C</i>, satisfies \(C˘ = ∼E\); i.e., any linear
          order ‘⊑’ satisfies \(∀ x, y •\quad ¬ (x ⊑ y) \;≡\; y ⊏
          x\).</p>
          <p>Likewise, for liner order, we have <i>transitivity
          E⨾C⨾E = C</i> and <i>weakening C ⊆ E</i>; i.e., \(a ⊑ b ⊏
          c ⊑ d \;⇒\; a ⊏ d \quad\; and\; \quad x ⊏ y \;⇒\; x ⊑
          y\).</p>
          <p>Every order <i>E</i> can be extended to a linear order
          <i>E′</i>; i.e., <i>E ⊆ E′</i>. For the finite case this
          is known as <i>topological sort</i>, and for the infinite
          case this is known as the <i>Szpilrajn extension</i>.</p>
          <ul class="org-ul">
            <li>
              <p>For the finite case, the <i>idea</i> is as
              follows: If <i>E</i> is not linear, then there are
              two incomparable elements <i>x, y</i> (i.e., outside
              <i>E ∪ E˘</i>), so we may define <i>an</i> ordering
              <i>E₁ ≔ E ∪ {(x, y)}</i>. We iterate this process and
              <i>Eₙ</i> will eventually become linear.</p>
              <p>This process maintains “the order <i>E</i>, less
              the incomparable elements, is linear” invariant
              throughout. Since each step reduces the number of
              incomparable elements, it must terminate, and the
              invariant then ensures the resulting order is linear.
              (•̀ᴗ•́)و</p>
            </li>
          </ul>
        </div>
        <p><abbr class="tooltip" title=
        "/Any two different members are related/; (the associated graph can be drawn&lt;br&gt;similar to a line).&lt;br&gt;&lt;br&gt;( In graph terminology, semilinear is also referred to as &lt;em&gt;complete&lt;/em&gt;; e.g., &lt;em&gt;“the&lt;br&gt;complete graph on n nodes”&lt;/em&gt; refers to &lt;em&gt;⊤ ∩ ∼Id : 1..n ↔ 1..n&lt;/em&gt;. )&lt;br&gt;&lt;br&gt;  &lt;EM&gt;R&lt;/EM&gt; is semilinear&lt;br&gt;≡ &lt;em&gt;∀ x, y • x ≠ y ⇒ x 〔R〕 y ∨ y 〔R〕 x&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∼Id ⊆ R ∪ R ˘&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∼ R ⊆ R ˘ ∪ Id&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∼ R&lt;/em&gt; is antisymmetric&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.&lt;br&gt;&lt;br&gt;A relation without incomparable elements is semilinear.&lt;br&gt;&lt;br&gt;A semilinear and asymmetric relation &lt;EM&gt;R&lt;/EM&gt; is known as a &lt;em&gt;tournament&lt;/em&gt; since it&lt;br&gt;models the win-loss situation of a typical sports tournament: Semilinearity and&lt;br&gt;asymmetry ensure teams do not play against themselves and that there is no draw&lt;br&gt;---i.e., there must be a winner. A tournament &lt;em&gt;R&lt;/em&gt; is characterised by &lt;em&gt;R ∪ R˘ =&lt;br&gt;∼Id&lt;/em&gt;.">
        Semilinear</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Semilinear</h3>
          <p><i>Any two different members are related</i>; (the
          associated graph can be drawn similar to a line).</p>
          <p>( In graph terminology, semilinear is also referred to
          as <i>complete</i>; e.g., <i>“the complete graph on n
          nodes”</i> refers to \(⊤ ∩ ∼Id : 1..n ↔ 1..n\). )</p>
          <p>\(R\) is semilinear ≡ <i>∀ x, y • x ≠ y ⇒ x 〔R〕 y ∨ y
          〔R〕 x</i> ≡ \(∼Id ⊆ R ∪ R ˘\) ≡ \(∼ R ⊆ R ˘ ∪ Id\) ≡ \(∼
          R\) is antisymmetric</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
          <p>A relation without incomparable elements is
          semilinear.</p>
          <p>A semilinear and asymmetric relation \(R\) is known as
          a <i>tournament</i> since it models the win-loss
          situation of a typical sports tournament: Semilinearity
          and asymmetry ensure teams do not play against themselves
          and that there is no draw —i.e., there must be a winner.
          A tournament <i>R</i> is characterised by <i>R ∪ R˘ =
          ∼Id</i>.</p>
        </div>
      </div>
    </div>
    <div id=
    "outline-container-Properties-of-Heterogeneous-Relations"
    class="outline-2">
      <h2 id="Properties-of-Heterogeneous-Relations"><span class=
      "section-number-2">4.</span> Properties of
      <i>Heterogeneous</i> Relations</h2>
      <div class="outline-text-2" id=
      "text-Properties-of-Heterogeneous-Relations">
        <p><abbr class="tooltip" title=
        "&lt;strong&gt;Univalent (partially defined function):&lt;/strong&gt; &lt;em&gt;Equal elements are related to equal&lt;br&gt;elements; i.e., an element cannot be related to two different elements.&lt;/em&gt;&lt;br&gt;&lt;br&gt;&lt;em&gt;That is, every source value x is associated &lt;strong&gt;at most one&lt;/strong&gt; target value y.&lt;/em&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;A relation &lt;EM&gt;R : V → V&lt;/EM&gt; can be visualised as a drawing: A dot for each element&lt;br&gt;&lt;em&gt;x&lt;/em&gt; of &lt;EM&gt;V&lt;/EM&gt;, and a directed line &lt;em&gt;x ⟶ y&lt;/em&gt; between two points exactly when &lt;em&gt;x 〔R〕&lt;br&gt;y&lt;/em&gt;. That is relations are &lt;em&gt;simple graphs&lt;/em&gt;; one refers to the directed lines&lt;br&gt;as &lt;em&gt;edges&lt;/em&gt; and the dots as &lt;em&gt;nodes&lt;/em&gt;.&lt;br&gt;&lt;br&gt;As a simple graph, univalence means: &lt;em&gt;Any arcs from the same source actually coincide.&lt;/em&gt;&lt;br&gt;That is, &lt;em&gt;Every node has at most one outgoing edge.&lt;/em&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;  &lt;EM&gt;R&lt;/EM&gt; is univalent&lt;br&gt;≡ &lt;em&gt;∀ x, y, y′ • x 〔 R 〕 y ∧ x 〔R〕 y′ ⇒ y = y′&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;R ˘ ⨾ R ⊆ Id&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;R ⨾ ∼ Id  ⊆  ∼ R&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∀ S • R ⨾ ∼ S  ⊆  ∼ (R ⨾ S)&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∀ S • R ⨾ ∼ S = R ⨾ ⊤ ∩ ∼(R ⨾ S)&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∀ Q, S • R ⨾ (Q ∩ S) = R ⨾ Q ∩ R ⨾ S&lt;/em&gt;  ---c.f., ⨾ sub-distributes over ∩&lt;br&gt;≡ &lt;em&gt;∀ Q, S • Q⨾R ∩ S = (Q ∩ S ⨾ R˘)⨾R&lt;/em&gt;    ---c.f., the Dedekind rule&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.&lt;br&gt;&lt;hr&gt;&lt;br&gt;The formula &lt;em&gt;R ⨾ ∼ Id  ⊆ ∼ R&lt;/em&gt; reads “If &lt;em&gt;x&lt;/em&gt; is &lt;em&gt;R&lt;/em&gt;-related to a value different&lt;br&gt;from &lt;em&gt;y&lt;/em&gt;, then it is not &lt;em&gt;R&lt;/em&gt;-related to &lt;em&gt;y&lt;/em&gt;.” It continues to hold when we replace&lt;br&gt;the identity by an arbitrary relation.&lt;br&gt;&lt;br&gt;The 5th row reads, &lt;em&gt;the preimage of the complement is the same as the complement&lt;br&gt;of the preimage intersected with the domain&lt;/em&gt;. In fact, for univalent &lt;EM&gt;R&lt;/EM&gt;, we&lt;br&gt;also have &lt;em&gt;∼(R ⨾ S) = R ⨾ ∼ S ∪ ∼(R ⨾ ⊤)&lt;/em&gt;; e.g., the people who do “not (own an&lt;br&gt;Audi car)” are exactly the people who “(own a non-Audi car) or do not(own any&lt;br&gt;car)” ---assuming a person can own at most one car.&lt;br&gt;&lt;br&gt;For a map &lt;em&gt;f&lt;/em&gt;, the 6th row becomes: &lt;em&gt;f(A ∩ B)  =  f(A) ∩ f(B)&lt;/em&gt;, using&lt;br&gt;conventional direct image notation; i.e., for a function, &lt;em&gt;the preimage of an&lt;br&gt;intersection is the intersection of preimages&lt;/em&gt;.&lt;br&gt;&lt;br&gt;Likewise, for a map &lt;em&gt;f&lt;/em&gt;, we have &lt;em&gt;the intersection of &lt;EM&gt;B&lt;/EM&gt; with a function's image&lt;br&gt;is the same as the image of an intersection involving the preimage of &lt;EM&gt;B&lt;/EM&gt;&lt;/em&gt;; i.e.,&lt;br&gt;&lt;em&gt;f(A) ∩ B = f(A ∩ f^{-1}(B))&lt;/em&gt;.">
        Univalent</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Univalent</h3>
          <p><b>Univalent (partially defined function):</b>
          <i>Equal elements are related to equal elements; i.e., an
          element cannot be related to two different
          elements.</i></p>
          <p><i>That is, every source value x is associated <b>at
          most one</b> target value y.</i></p>
          <hr>
          <p>A relation \(R : V → V\) can be visualised as a
          drawing: A dot for each element \(x\) of \(V\), and a
          directed line \(x ⟶ y\) between two points exactly when
          \(x 〔R〕 y\). That is relations are <i>simple graphs</i>;
          one refers to the directed lines as <i>edges</i> and the
          dots as <i>nodes</i>.</p>
          <p>As a simple graph, univalence means: <i>Any arcs from
          the same source actually coincide.</i> That is, <i>Every
          node has at most one outgoing edge.</i></p>
          <hr>
          <p>\(R\) is univalent ≡ <i>∀ x, y, y′ • x 〔 R 〕 y ∧ x 〔R〕
          y′ ⇒ y = y′</i> ≡ \(R ˘ ⨾ R ⊆ Id\) ≡ \(R ⨾ ∼ Id \;⊆\; ∼
          R\) ≡ \(∀ S • R ⨾ ∼ S \;⊆\; ∼ (R ⨾ S)\) ≡ <i>∀ S • R ⨾ ∼
          S = R ⨾ ⊤ ∩ ∼(R ⨾ S)</i> ≡ <i>∀ Q, S • R ⨾ (Q ∩ S) = R ⨾
          Q ∩ R ⨾ S</i> —c.f., ⨾ sub-distributes over ∩ ≡ <i>∀ Q, S
          • Q⨾R ∩ S = (Q ∩ S ⨾ R˘)⨾R</i> —c.f., the Dedekind
          rule</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
          <hr>
          <p>The formula \(R ⨾ ∼ Id \;⊆ ∼ R\) reads “If <i>x</i> is
          <i>R</i>-related to a value different from <i>y</i>, then
          it is not <i>R</i>-related to <i>y</i>.” It continues to
          hold when we replace the identity by an arbitrary
          relation.</p>
          <p>The 5th row reads, <i>the preimage of the complement
          is the same as the complement of the preimage intersected
          with the domain</i>. In fact, for univalent \(R\), we
          also have \(∼(R ⨾ S) = R ⨾ ∼ S ∪ ∼(R ⨾ ⊤)\); e.g., the
          people who do “not (own an Audi car)” are exactly the
          people who “(own a non-Audi car) or do not(own any car)”
          —assuming a person can own at most one car.</p>
          <p>For a map \(f\), the 6th row becomes: \(f(A ∩ B) \;=\;
          f(A) ∩ f(B)\), using conventional direct image notation;
          i.e., for a function, <i>the preimage of an intersection
          is the intersection of preimages</i>.</p>
          <p>Likewise, for a map \(f\), we have <i>the intersection
          of \(B\) with a function’s image is the same as the image
          of an intersection involving the preimage of \(B\)</i>;
          i.e., \(f(A) ∩ B = f(A ∩ f^{-1}(B))\).</p>
        </div>
        <p><abbr class="tooltip" title=
        "&lt;strong&gt;Total:&lt;/strong&gt; &lt;em&gt;Every source value x is associated &lt;strong&gt;at least one&lt;/strong&gt; target value y.&lt;/em&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;A relation &lt;EM&gt;R : V → V&lt;/EM&gt; can be visualised as a drawing: A dot for each element&lt;br&gt;&lt;em&gt;x&lt;/em&gt; of &lt;EM&gt;V&lt;/EM&gt;, and a directed line &lt;em&gt;x ⟶ y&lt;/em&gt; between two points exactly when &lt;em&gt;x 〔R〕&lt;br&gt;y&lt;/em&gt;. That is relations are &lt;em&gt;simple graphs&lt;/em&gt;; one refers to the directed lines&lt;br&gt;as &lt;em&gt;edges&lt;/em&gt; and the dots as &lt;em&gt;nodes&lt;/em&gt;.&lt;br&gt;&lt;br&gt;As a simple graph, totality means: &lt;em&gt;Every node has at least one outgoing edge&lt;/em&gt;.&lt;br&gt;&lt;br&gt;  &lt;EM&gt;R&lt;/EM&gt; is total&lt;br&gt;≡ &lt;em&gt;∀ x • ∃ y • x 〔 R 〕 y&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;⊤ = R ⨾ ⊤&lt;/em&gt; (“defined everywhere”)&lt;br&gt;≡ &lt;em&gt;⊥ = ∼ (R ⨾ ⊤)&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;Id ⊆ R ⨾ R ˘&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∼ R  ⊆  R ⨾ ∼ Id&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∀ S • ∼ (R ⨾ S)  ⊆  R ⨾ ∼ S&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∀ Q • Q ⨾ R = ⊥ ≡ Q = ⊥&lt;/em&gt;&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.&lt;br&gt;&lt;hr&gt;&lt;br&gt;The formula &lt;em&gt;∼ R  ⊆  R ⨾ ∼ Id&lt;/em&gt; reads “If &lt;em&gt;x&lt;/em&gt; is not &lt;em&gt;R&lt;/em&gt;-related to y, then &lt;em&gt;x&lt;/em&gt; is &lt;em&gt;R&lt;/em&gt;&lt;br&gt;related to some element different from &lt;em&gt;y&lt;/em&gt;.” It continues to hold when we replace&lt;br&gt;the identity by an arbitrary relation.&lt;br&gt;&lt;br&gt;The final formula says that &lt;EM&gt;R&lt;/EM&gt; is post-annihilated by the empty relation only.&lt;br&gt;&lt;br&gt;Note: &lt;em&gt;∼(R ⨾ ⊤) = ⊤  ≡  R = ⊥&lt;/em&gt;, for any &lt;EM&gt;R&lt;/EM&gt;; i.e., &lt;em&gt;the complement of a&lt;br&gt;relation's domain is everything precisely when the relation is empty.&lt;/em&gt;">
        Total</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Total</h3>
          <p><b>Total:</b> <i>Every source value x is associated
          <b>at least one</b> target value y.</i></p>
          <hr>
          <p>A relation \(R : V → V\) can be visualised as a
          drawing: A dot for each element \(x\) of \(V\), and a
          directed line \(x ⟶ y\) between two points exactly when
          \(x 〔R〕 y\). That is relations are <i>simple graphs</i>;
          one refers to the directed lines as <i>edges</i> and the
          dots as <i>nodes</i>.</p>
          <p>As a simple graph, totality means: <i>Every node has
          at least one outgoing edge</i>.</p>
          <p>\(R\) is total ≡ <i>∀ x • ∃ y • x 〔 R 〕 y</i> ≡ \(⊤ =
          R ⨾ ⊤\) (“defined everywhere”) ≡ \(⊥ = ∼ (R ⨾ ⊤)\) ≡ \(Id
          ⊆ R ⨾ R ˘\) ≡ \(∼ R \;⊆\; R ⨾ ∼ Id\) ≡ \(∀ S • ∼ (R ⨾ S)
          \;⊆\; R ⨾ ∼ S\) ≡ \(∀ Q • Q ⨾ R = ⊥ ≡ Q = ⊥\)</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
          <hr>
          <p>The formula \(∼ R \;⊆\; R ⨾ ∼ Id\) reads “If <i>x</i>
          is not <i>R</i>-related to y, then <i>x</i> is <i>R</i>
          related to some element different from <i>y</i>.” It
          continues to hold when we replace the identity by an
          arbitrary relation.</p>
          <p>The final formula says that \(R\) is post-annihilated
          by the empty relation only.</p>
          <p>Note: \(∼(R ⨾ ⊤) = ⊤ \;≡\; R = ⊥\), for any \(R\);
          i.e., <i>the complement of a relation’s domain is
          everything precisely when the relation is empty.</i></p>
        </div>
        <p><abbr class="tooltip" title=
        "&lt;strong&gt;Map (totally defined function):&lt;/strong&gt; &lt;em&gt;Every source value x is associated &lt;strong&gt;exactly one&lt;/strong&gt;&lt;br&gt;target value y.&lt;/em&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;A relation &lt;EM&gt;R : V → V&lt;/EM&gt; can be visualised as a drawing: A dot for each element&lt;br&gt;&lt;em&gt;x&lt;/em&gt; of &lt;EM&gt;V&lt;/EM&gt;, and a directed line &lt;em&gt;x ⟶ y&lt;/em&gt; between two points exactly when &lt;em&gt;x 〔R〕&lt;br&gt;y&lt;/em&gt;. That is relations are &lt;em&gt;simple graphs&lt;/em&gt;; one refers to the directed lines&lt;br&gt;as &lt;em&gt;edges&lt;/em&gt; and the dots as &lt;em&gt;nodes&lt;/em&gt;.&lt;br&gt;&lt;br&gt;As a simple relation, being a mapping means: &lt;em&gt;Every node has exactly one outgoing edge.&lt;/em&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;  &lt;EM&gt;F&lt;/EM&gt; is a map&lt;br&gt;≡ &lt;EM&gt;F&lt;/EM&gt; is total and univalent&lt;br&gt;≡ &lt;em&gt;F ⨾ ∼ Id  =  ∼ F&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∀ S • F ⨾ ∼ S  =  ∼ (F ⨾ S)&lt;/em&gt;&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.&lt;br&gt;&lt;hr&gt;&lt;br&gt;The final rule says &lt;em&gt;the preimage of the complement is the complement of the&lt;br&gt;preimage&lt;/em&gt;; or, using conventional direct image notation, &lt;em&gt;f⁻¹(∼ A)  =  ∼&lt;br&gt;f⁻¹(A)&lt;/em&gt;.&lt;br&gt;&lt;br&gt;In conventional direct image notation, this amount to a Galois connection: &lt;em&gt;A ⊆&lt;br&gt;f⁻¹(B)  ≡  f(A) ⊆ B&lt;/em&gt;.&lt;br&gt;&lt;br&gt;A mapping is so very close to being invertible since mappings &lt;EM&gt;F&lt;/EM&gt; always&lt;br&gt;satisfy: &lt;em&gt;F ˘ ⨾ F ⊆ Id&lt;/em&gt; and &lt;em&gt;Id ⊆ F ⨾ F˘&lt;/em&gt;.&lt;br&gt;&lt;br&gt;Shunting rule:* If &lt;EM&gt;F&lt;/EM&gt; is a map, then &lt;em&gt;R ⊆ S ⨾ F ˘  ≡  R ⨾ F ⊆ S&lt;/em&gt;.&lt;br&gt;&lt;br&gt;More generally, given an equivalence Ξ, if relation &lt;em&gt;F&lt;/em&gt; is total and Ξ-univalent&lt;br&gt;---i.e., &lt;em&gt;F˘ ⨾ F ⊆ Ξ&lt;/em&gt;--- and if &lt;em&gt;S&lt;/em&gt; is Ξ-target-saturated ---i.e., &lt;em&gt;S ⨾ Ξ = S&lt;/em&gt;---&lt;br&gt;then &lt;em&gt;R ⊆ S ⨾ F ˘  ≡  R ⨾ F ⊆ S&lt;/em&gt;.">
        Map</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Map</h3>
          <p><b>Map (totally defined function):</b> <i>Every source
          value x is associated <b>exactly one</b> target value
          y.</i></p>
          <hr>
          <p>A relation \(R : V → V\) can be visualised as a
          drawing: A dot for each element \(x\) of \(V\), and a
          directed line \(x ⟶ y\) between two points exactly when
          \(x 〔R〕 y\). That is relations are <i>simple graphs</i>;
          one refers to the directed lines as <i>edges</i> and the
          dots as <i>nodes</i>.</p>
          <p>As a simple relation, being a mapping means: <i>Every
          node has exactly one outgoing edge.</i></p>
          <hr>
          <p>\(F\) is a map ≡ \(F\) is total and univalent ≡ \(F ⨾
          ∼ Id \;=\; ∼ F\) ≡ \(∀ S • F ⨾ ∼ S \;=\; ∼ (F ⨾ S)\)</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
          <hr>
          <p>The final rule says <i>the preimage of the complement
          is the complement of the preimage</i>; or, using
          conventional direct image notation, \(f⁻¹(∼ A) \;=\; ∼
          f⁻¹(A)\).</p>
          <p>In conventional direct image notation, this amount to
          a Galois connection: \(A ⊆ f⁻¹(B) \quad≡\quad f(A) ⊆
          B\).</p>
          <p>A mapping is so very close to being invertible since
          mappings \(F\) always satisfy: \(F ˘ ⨾ F ⊆ Id\) and \(Id
          ⊆ F ⨾ F˘\).</p>
          <p>Shunting rule:* If \(F\) is a map, then \(R ⊆ S ⨾ F ˘
          \quad≡\quad R ⨾ F ⊆ S\).</p>
          <p>More generally, given an equivalence Ξ, if relation
          <i>F</i> is total and Ξ-univalent —i.e., <i>F˘ ⨾ F ⊆
          Ξ</i>— and if <i>S</i> is Ξ-target-saturated —i.e., <i>S
          ⨾ Ξ = S</i>— then \(R ⊆ S ⨾ F ˘ \quad≡\quad R ⨾ F ⊆
          S\).</p>
        </div>
        <p><abbr class="tooltip" title=
        "&lt;strong&gt;Surjective:&lt;/strong&gt; &lt;em&gt;Every source value y is associated &lt;strong&gt;at least&lt;/strong&gt; one source value x.&lt;/em&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;A relation &lt;EM&gt;R : V → V&lt;/EM&gt; can be visualised as a drawing: A dot for each element&lt;br&gt;&lt;em&gt;x&lt;/em&gt; of &lt;EM&gt;V&lt;/EM&gt;, and a directed line &lt;em&gt;x ⟶ y&lt;/em&gt; between two points exactly when &lt;em&gt;x 〔R〕&lt;br&gt;y&lt;/em&gt;. That is relations are &lt;em&gt;simple graphs&lt;/em&gt;; one refers to the directed lines&lt;br&gt;as &lt;em&gt;edges&lt;/em&gt; and the dots as &lt;em&gt;nodes&lt;/em&gt;.&lt;br&gt;&lt;br&gt;As a simple graph, surjectivity means: &lt;em&gt;Every node has at least one incoming edge.&lt;/em&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;  &lt;EM&gt;R&lt;/EM&gt; is surjective&lt;br&gt;≡ &lt;EM&gt;R˘&lt;/EM&gt; is total&lt;br&gt;≡ &lt;em&gt;⊤ ⨾ R = ⊤&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;Id ⊆ R ˘ ⨾ R&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∼ R  ⊆  ∼ Id ⨾ R&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∀ S • R ⨾ S = ⊥ ≡ S = ⊥&lt;/em&gt;&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.">
        Surjective</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Surjective</h3>
          <p><b>Surjective:</b> <i>Every source value y is
          associated <b>at least</b> one source value x.</i></p>
          <hr>
          <p>A relation \(R : V → V\) can be visualised as a
          drawing: A dot for each element \(x\) of \(V\), and a
          directed line \(x ⟶ y\) between two points exactly when
          \(x 〔R〕 y\). That is relations are <i>simple graphs</i>;
          one refers to the directed lines as <i>edges</i> and the
          dots as <i>nodes</i>.</p>
          <p>As a simple graph, surjectivity means: <i>Every node
          has at least one incoming edge.</i></p>
          <hr>
          <p>\(R\) is surjective ≡ \(R˘\) is total ≡ \(⊤ ⨾ R = ⊤\)
          ≡ \(Id ⊆ R ˘ ⨾ R\) ≡ \(∼ R \;⊆\; ∼ Id ⨾ R\) ≡ <i>∀ S • R
          ⨾ S = ⊥ ≡ S = ⊥</i></p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
        </div>
        <p><abbr class="tooltip" title=
        "&lt;strong&gt;Injective:&lt;/strong&gt; &lt;em&gt;Every source value y is associated &lt;strong&gt;at most&lt;/strong&gt; one source value x.&lt;/em&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;A relation &lt;EM&gt;R : V → V&lt;/EM&gt; can be visualised as a drawing: A dot for each element&lt;br&gt;&lt;em&gt;x&lt;/em&gt; of &lt;EM&gt;V&lt;/EM&gt;, and a directed line &lt;em&gt;x ⟶ y&lt;/em&gt; between two points exactly when &lt;em&gt;x 〔R〕&lt;br&gt;y&lt;/em&gt;. That is relations are &lt;em&gt;simple graphs&lt;/em&gt;; one refers to the directed lines&lt;br&gt;as &lt;em&gt;edges&lt;/em&gt; and the dots as &lt;em&gt;nodes&lt;/em&gt;.&lt;br&gt;&lt;br&gt;As a simple graph, injective means: &lt;em&gt;Every node has at most one incoming edge.&lt;/em&gt;&lt;br&gt;&lt;hr&gt;&lt;br&gt;  &lt;EM&gt;R&lt;/EM&gt; is injective&lt;br&gt;≡ &lt;EM&gt;R˘&lt;/EM&gt; is univalent&lt;br&gt;≡ &lt;em&gt;R ⨾ R ˘ ⊆ Id&lt;/em&gt;&lt;br&gt;≡ &lt;em&gt;∼ Id ⨾ R  ⊆  ∼ R&lt;/em&gt;&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.">
        Injective</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Injective</h3>
          <p><b>Injective:</b> <i>Every source value y is
          associated <b>at most</b> one source value x.</i></p>
          <hr>
          <p>A relation \(R : V → V\) can be visualised as a
          drawing: A dot for each element \(x\) of \(V\), and a
          directed line \(x ⟶ y\) between two points exactly when
          \(x 〔R〕 y\). That is relations are <i>simple graphs</i>;
          one refers to the directed lines as <i>edges</i> and the
          dots as <i>nodes</i>.</p>
          <p>As a simple graph, injective means: <i>Every node has
          at most one incoming edge.</i></p>
          <hr>
          <p>\(R\) is injective ≡ \(R˘\) is univalent ≡ \(R ⨾ R ˘ ⊆
          Id\) ≡ \(∼ Id ⨾ R \;⊆\; ∼ R\)</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
        </div>
        <p><abbr class="tooltip" title=
        "&lt;strong&gt;Bijective:&lt;/strong&gt; &lt;em&gt;Every source value y is associated &lt;strong&gt;exactly one&lt;/strong&gt; source value x.&lt;/em&gt;&lt;br&gt;&lt;br&gt;  &lt;EM&gt;R&lt;/EM&gt; is bijective&lt;br&gt;≡ &lt;EM&gt;R&lt;/EM&gt; is injective and surjective&lt;br&gt;&lt;hr&gt;&lt;br&gt;A relation &lt;EM&gt;R : V → V&lt;/EM&gt; can be visualised as a drawing: A dot for each element&lt;br&gt;&lt;em&gt;x&lt;/em&gt; of &lt;EM&gt;V&lt;/EM&gt;, and a directed line &lt;em&gt;x ⟶ y&lt;/em&gt; between two points exactly when &lt;em&gt;x 〔R〕&lt;br&gt;y&lt;/em&gt;. That is relations are &lt;em&gt;simple graphs&lt;/em&gt;; one refers to the directed lines&lt;br&gt;as &lt;em&gt;edges&lt;/em&gt; and the dots as &lt;em&gt;nodes&lt;/em&gt;.&lt;br&gt;&lt;br&gt;As a simple graph, bijectivity means: &lt;em&gt;Every node has exactly one outgoing edge&lt;/em&gt;.">
        Bijective</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Bijective</h3>
          <p><b>Bijective:</b> <i>Every source value y is
          associated <b>exactly one</b> source value x.</i></p>
          <p>\(R\) is bijective ≡ \(R\) is injective and
          surjective</p>
          <hr>
          <p>A relation \(R : V → V\) can be visualised as a
          drawing: A dot for each element \(x\) of \(V\), and a
          directed line \(x ⟶ y\) between two points exactly when
          \(x 〔R〕 y\). That is relations are <i>simple graphs</i>;
          one refers to the directed lines as <i>edges</i> and the
          dots as <i>nodes</i>.</p>
          <p>As a simple graph, bijectivity means: <i>Every node
          has exactly one outgoing edge</i>.</p>
        </div>
        <p><abbr class="tooltip" title=
        "An &lt;strong&gt;iso&lt;/strong&gt; is a bijective mapping, also known as a &lt;strong&gt;permutation.&lt;/strong&gt;&lt;br&gt;&lt;br&gt;An isomorphism is a non-lossy protocol associating inputs to outputs.&lt;br&gt;&lt;hr&gt;&lt;br&gt;A relation &lt;EM&gt;R : V → V&lt;/EM&gt; can be visualised as a drawing: A dot for each element&lt;br&gt;&lt;em&gt;x&lt;/em&gt; of &lt;EM&gt;V&lt;/EM&gt;, and a directed line &lt;em&gt;x ⟶ y&lt;/em&gt; between two points exactly when &lt;em&gt;x 〔R〕&lt;br&gt;y&lt;/em&gt;. That is relations are &lt;em&gt;simple graphs&lt;/em&gt;; one refers to the directed lines&lt;br&gt;as &lt;em&gt;edges&lt;/em&gt; and the dots as &lt;em&gt;nodes&lt;/em&gt;.&lt;br&gt;&lt;br&gt;As a simple graph, an iso is a &lt;em&gt;bunch of circles&lt;/em&gt;: Any number of cycles, such that&lt;br&gt;every node lies on exactly one.&lt;br&gt;&lt;hr&gt;&lt;br&gt;If relation &lt;EM&gt;R&lt;/EM&gt; is finite, then&lt;br&gt;&lt;em&gt;R ⨾ R ˘ = Id  ≡  (∃ m • Rᵐ = Id ∧ Rᵐ⁻¹ = R ˘)&lt;/em&gt;&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.">
        Iso</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Iso</h3>
          <p>An <b>iso</b> is a bijective mapping, also known as a
          <b>permutation.</b></p>
          <p>An isomorphism is a non-lossy protocol associating
          inputs to outputs.</p>
          <hr>
          <p>A relation \(R : V → V\) can be visualised as a
          drawing: A dot for each element \(x\) of \(V\), and a
          directed line \(x ⟶ y\) between two points exactly when
          \(x 〔R〕 y\). That is relations are <i>simple graphs</i>;
          one refers to the directed lines as <i>edges</i> and the
          dots as <i>nodes</i>.</p>
          <p>As a simple graph, an iso is a <i>bunch of
          circles</i>: Any number of cycles, such that every node
          lies on exactly one.</p>
          <hr>
          <p>If relation \(R\) is finite, then \(R ⨾ R ˘ = Id
          \quad≡\quad (∃ m • Rᵐ = Id ∧ Rᵐ⁻¹ = R ˘)\)</p>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
        </div>
        <p><abbr class="tooltip" title=
        "This property generalises injectivity, univalence, and equivalence...&lt;br&gt;&lt;br&gt;Recall,&lt;br&gt;- Univalent: Every source value &lt;em&gt;x&lt;/em&gt; is associated &lt;strong&gt;at most one&lt;/strong&gt; target value &lt;em&gt;y&lt;/em&gt;.&lt;br&gt;  + I.e., if &lt;em&gt;x&lt;/em&gt; goes to &lt;em&gt;y&lt;/em&gt; and &lt;em&gt;y′&lt;/em&gt; then &lt;em&gt;y = y′&lt;/em&gt;.&lt;br&gt;  + I.e., &lt;em&gt;∀ x, y′, y •  x 〔R〕 y 〔R˘〕 x 〔R〕 y′  ⇒  y 〔Id〕 y′&lt;/em&gt;&lt;br&gt;- Injective: Every source value &lt;em&gt;y&lt;/em&gt; is associated &lt;strong&gt;at most&lt;/strong&gt; one source value &lt;em&gt;x&lt;/em&gt;.&lt;br&gt;  + I.e., if &lt;em&gt;y&lt;/em&gt; comes from &lt;em&gt;x&lt;/em&gt; and &lt;em&gt;x′&lt;/em&gt; then &lt;em&gt;x = x′&lt;/em&gt;.&lt;br&gt;  + I.e., &lt;em&gt;∀ x, x′, y •  x 〔R〕 y 〔R˘〕 x′ 〔R〕 y  ⇒  x 〔Id〕 x′&lt;/em&gt;&lt;br&gt;- Equivalence: Any given equivalence classes are either identical or disjoint.&lt;br&gt;   # + I.e., &lt;em&gt;∀ x, y •  x 〔R〕 y 〔R˘〕 x 〔R〕 y′  ⇒  x 〔R〕 y′&lt;/em&gt;&lt;br&gt;  + Moreover, it is a &lt;em&gt;homogenous&lt;/em&gt; relation.&lt;br&gt;&lt;br&gt; Now, a &lt;em&gt;possibly heterogenous&lt;/em&gt; relation &lt;em&gt;R&lt;/em&gt; is &lt;em&gt;difunctional&lt;/em&gt; exactly when&lt;br&gt; &lt;em&gt;∀ x, x′, y′, y •  x 〔R〕 y 〔R˘〕 x′ 〔R〕 y′  ⇒  x 〔R〕 y′&lt;/em&gt;.&lt;br&gt; That is, &lt;EM&gt;R ⨾ R ˘ ⨾ R ⊆ R&lt;/EM&gt;; in-fact we have equality &lt;EM&gt;R ⨾ R ˘ ⨾ R = R&lt;/EM&gt;.&lt;br&gt; Using Schröder, this amounts to &lt;EM&gt;R ⨾ ∼R ˘ ⨾ R  ⊆  ∼R&lt;/EM&gt;.&lt;br&gt;&lt;br&gt; Clearly, converse preserves difunctionality.&lt;br&gt;&lt;br&gt; For difunctional &lt;em&gt;R&lt;/em&gt;,&lt;br&gt; 1. &lt;em&gt;R ⨾ (Q ∩ R˘ ⨾ S) = R ⨾ Q ∩ R ⨾ R˘ ⨾ S&lt;/em&gt;&lt;br&gt; 2. &lt;EM&gt;R ⨾ ∼(R ˘ ⨾ Q)  =  R ⨾ ⊤ ∩ ∼(R ⨾ R˘ Q)&lt;/EM&gt;&lt;br&gt; 3. &lt;em&gt;∼(R ⨾ R ˘ ⨾ Q)  =  R ⨾ ∼(R˘ ⨾ Q) ∪ ∼(R ⨾ ⊤)&lt;/em&gt;&lt;br&gt; 4. &lt;EM&gt;R ⨾ ∼(R ˘ ⨾ Q)  =  ∼(R ⨾ R˘ Q)&lt;/EM&gt;, if &lt;em&gt;R&lt;/em&gt; is also total.&lt;br&gt;&lt;br&gt;Where &lt;em&gt;⨾, ⊤, ⊥, Id, ˘, ∼&lt;/em&gt; are relation composition, the universal relation, the&lt;br&gt;empty relation, the identity relation, relation converse (transpose), and complement.&lt;br&gt;&lt;hr&gt;&lt;br&gt;The equivalence target-saturation of a univalent relation is difunctional; i.e.,&lt;br&gt;if &lt;em&gt;R&lt;/em&gt; is univalent and Ξ is an equivalence, then &lt;EM&gt;R ⨾ Ξ&lt;/EM&gt; is difunctional.">
        Difunctional</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Difunctional</h3>
          <p>This property generalises injectivity, univalence, and
          equivalence…</p>
          <p>Recall,</p>
          <ul class="org-ul">
            <li>Univalent: Every source value <i>x</i> is
            associated <b>at most one</b> target value <i>y</i>.
              <ul class="org-ul">
                <li>I.e., if <i>x</i> goes to <i>y</i> and
                <i>y′</i> then <i>y = y′</i>.</li>
                <li>I.e., \(∀ x, y′, y •\quad x 〔R〕 y 〔R˘〕 x 〔R〕 y′
                \;⇒\; y 〔Id〕 y′\)</li>
              </ul>
            </li>
            <li>Injective: Every source value <i>y</i> is
            associated <b>at most</b> one source value <i>x</i>.
              <ul class="org-ul">
                <li>I.e., if <i>y</i> comes from <i>x</i> and
                <i>x′</i> then <i>x = x′</i>.</li>
                <li>I.e., \(∀ x, x′, y •\quad x 〔R〕 y 〔R˘〕 x′ 〔R〕 y
                \;⇒\; x 〔Id〕 x′\)</li>
              </ul>
            </li>
            <li>
              <p>Equivalence: Any given equivalence classes are
              either identical or disjoint.</p>
              <ul class="org-ul">
                <li>Moreover, it is a <i>homogenous</i>
                relation.</li>
              </ul>
              <p>Now, a <i>possibly heterogenous</i> relation
              <i>R</i> is <i>difunctional</i> exactly when \(∀ x,
              x′, y′, y •\quad x 〔R〕 y 〔R˘〕 x′ 〔R〕 y′ \;⇒\; x 〔R〕
              y′\). That is, \(R ⨾ R ˘ ⨾ R ⊆ R\); in-fact we have
              equality \(R ⨾ R ˘ ⨾ R = R\). Using Schröder, this
              amounts to \(R ⨾ ∼R ˘ ⨾ R \;⊆\; ∼R\).</p>
              <p>Clearly, converse preserves difunctionality.</p>
              <p>For difunctional <i>R</i>,</p>
              <ol class="org-ol">
                <li><i>R ⨾ (Q ∩ R˘ ⨾ S) = R ⨾ Q ∩ R ⨾ R˘ ⨾
                S</i></li>
                <li>\(R ⨾ ∼(R ˘ ⨾ Q) \;=\; R ⨾ ⊤ ∩ ∼(R ⨾ R˘
                Q)\)</li>
                <li>\(∼(R ⨾ R ˘ ⨾ Q) \;=\; R ⨾ ∼(R˘ ⨾ Q) ∪ ∼(R ⨾
                ⊤)\)</li>
                <li>\(R ⨾ ∼(R ˘ ⨾ Q) \;=\; ∼(R ⨾ R˘ Q)\), if
                <i>R</i> is also total.</li>
              </ol>
            </li>
          </ul>
          <p>Where <i>⨾, ⊤, ⊥, Id, ˘, ∼</i> are relation
          composition, the universal relation, the empty relation,
          the identity relation, relation converse (transpose), and
          complement.</p>
          <hr>
          <p>The equivalence target-saturation of a univalent
          relation is difunctional; i.e., if <i>R</i> is univalent
          and Ξ is an equivalence, then \(R ⨾ Ξ\) is
          difunctional.</p>
        </div>
      </div>
    </div>
    <div id="outline-container-orgc9bf56a" class="outline-2">
      <h2 id="orgc9bf56a"><span class="section-number-2">5.</span>
      Programming Development Relations</h2>
      <div class="outline-text-2" id="text-5">
        <p><abbr class="tooltip" title=
        "The Progressive JavaScript Framework !&lt;br&gt;&lt;br&gt;An approachable, performant and versatile framework for building web user interfaces.&lt;br&gt;&lt;br&gt;&lt;strong&gt;Installation&lt;/strong&gt;:&lt;br&gt;&lt;br&gt;=$ npm init vue@latest=&lt;br&gt;&lt;br&gt;&lt;strong&gt;Without Build Tools&lt;/strong&gt;:">
        Vue3</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>Vue3</h3>
          <p>The Progressive JavaScript Framework !</p>
          <p>An approachable, performant and versatile framework
          for building web user interfaces.</p>
          <p><b>Installation</b>:</p>
          <p><code>$ npm init vue@latest</code></p>
          <p><b>Without Build Tools</b>:</p>
        </div>
        <p><abbr class="tooltip" title=
        "Single File Component, 单文件组件，其中包含了 script , style , template, 三种标签&lt;br&gt;为一体的文件， vue 框架所使用的及推崇的一种新的开发方式。">
        SFC</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>SFC</h3>
          <p>Single File Component, 单文件组件，其中包含了 script , style ,
          template, 三种标签 为一体的文件， vue 框架所使用的及推崇的一种新的开发方式。</p>
        </div>
        <p><abbr class="tooltip" title=
        "Toggle the element's visibility based on the truthy-ness of the expression&lt;br&gt;value.&lt;br&gt;&lt;br&gt;Expects: &lt;strong&gt;any&lt;/strong&gt;&lt;br&gt;&lt;br&gt;Details&lt;br&gt;&lt;br&gt;&lt;strong&gt;v-show&lt;/strong&gt; works by setting the red:display CSS property via inline styles, and will try&lt;br&gt;to respect the initial display value when the element is visible. It also&lt;br&gt;triggers transitions when its condition changes.&lt;br&gt;&lt;br&gt;See also: Conditional Rendering - v-show (https://vuejs.org/guide/essentials/conditional.html#v-show)">
        v-show</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>v-show</h3>
          <p>Toggle the element’s visibility based on the
          truthy-ness of the expression value.</p>
          <p>Expects: <b>any</b></p>
          <p>Details</p>
          <p><b>v-show</b> works by setting the <span style=
          "color:red;">display</span> CSS property via inline
          styles, and will try to respect the initial display value
          when the element is visible. It also triggers transitions
          when its condition changes.</p>
          <p>See also: <a href=
          "https://vuejs.org/guide/essentials/conditional.html#v-show">
          Conditional Rendering - v-show</a></p>
        </div>
        <p><abbr class="tooltip" title=
        "&lt;strong&gt;3.2+&lt;/strong&gt;&lt;br&gt;&lt;br&gt;Expects: &lt;strong&gt;any[]&lt;/strong&gt;&lt;br&gt;&lt;br&gt;Details&lt;br&gt;&lt;br&gt;Memoize a sub-tree of the template. Can be used on both elements and components.&lt;br&gt;The directive expects a fixed-length array of dependency values to compare for&lt;br&gt;the memoization. If every value in the array was the same as last render, then&lt;br&gt;updates for the entire sub-tree will be skipped. For example:&lt;br&gt;&lt;br&gt;&lt;div v-memo=''[valueA, valueB]''&gt;&lt;br&gt; ...&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;br&gt;When the component re-renders, if both valueA and valueB remain the same, all&lt;br&gt;updates for this &lt;div&gt; and its children will be skipped. In fact, even the&lt;br&gt;Virtual DOM VNode creation will also be skipped since the memoized copy of the&lt;br&gt;sub-tree can be reused.&lt;br&gt;&lt;br&gt;It is important to specify the memoization array correctly, otherwise we may&lt;br&gt;skip updates that should indeed be applied. v-memo with an empty dependency&lt;br&gt;array (v-memo=''[]'') would be functionally equivalent to v-once.&lt;br&gt;&lt;br&gt;Usage with v-for&lt;br&gt;&lt;br&gt;v-memo is provided solely for micro optimizations in performance-critical&lt;br&gt;scenarios and should be rarely needed. The most common case where this may prove&lt;br&gt;helpful is when rendering large v-for lists (where length &gt; 1000):&lt;br&gt;&lt;br&gt;&lt;div v-for=''item in list'' :key=''item.id'' v-memo=''[item.id === selected]''&gt;&lt;br&gt; &lt;p&gt;ID: {{ item.id }} - selected: {{ item.id === selected }}&lt;/p&gt;&lt;br&gt; &lt;p&gt;...more child nodes&lt;/p&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;br&gt;When the component's selected state changes, a large amount of VNodes will be&lt;br&gt;created even though most of the items remained exactly the same. The v-memo&lt;br&gt;usage here is essentially saying ''only update this item if it went from&lt;br&gt;non-selected to selected, or the other way around''. This allows every unaffected&lt;br&gt;item to reuse its previous VNode and skip diffing entirely. Note we don't need&lt;br&gt;to include item.id in the memo dependency array here since Vue automatically&lt;br&gt;infers it from the item's :key.&lt;br&gt;&lt;br&gt;WARNING&lt;br&gt;&lt;br&gt;When using v-memo with v-for, make sure they are used on the same element.&lt;br&gt;v-memo does not work inside v-for.&lt;br&gt;&lt;br&gt;v-memo can also be used on components to manually prevent unwanted updates in&lt;br&gt;certain edge cases where the child component update check has been de-optimized.&lt;br&gt;But again, it is the developer's responsibility to specify correct dependency&lt;br&gt;arrays to avoid skipping necessary updates.&lt;br&gt;&lt;br&gt;See also:&lt;br&gt;&lt;br&gt;v-once (https://vuejs.org/api/built-in-directives.html#v-once)">
        v-memo</abbr></p>
        <div style=
        "padding: 1em; background-color: #CCFFFF;border-radius: 15px; font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em #00000057;">
          <h3>v-memo</h3>
          <p><b>3.2+</b></p>
          <p>Expects: <b>any[]</b></p>
          <p>Details</p>
          <p>Memoize a sub-tree of the template. Can be used on
          both elements and components. The directive expects a
          fixed-length array of dependency values to compare for
          the memoization. If every value in the array was the same
          as last render, then updates for the entire sub-tree will
          be skipped. For example:</p>
          <p>&lt;div v-memo=“[valueA, valueB]”&gt; …
          &lt;/div&gt;</p>
          <p>When the component re-renders, if both valueA and
          valueB remain the same, all updates for this &lt;div&gt;
          and its children will be skipped. In fact, even the
          Virtual DOM VNode creation will also be skipped since the
          memoized copy of the sub-tree can be reused.</p>
          <p>It is important to specify the memoization array
          correctly, otherwise we may skip updates that should
          indeed be applied. v-memo with an empty dependency array
          (v-memo=“[]”) would be functionally equivalent to
          v-once.</p>
          <p>Usage with v-for</p>
          <p>v-memo is provided solely for micro optimizations in
          performance-critical scenarios and should be rarely
          needed. The most common case where this may prove helpful
          is when rendering large v-for lists (where length &gt;
          1000):</p>
          <p>&lt;div v-for=“item in list” :key=“item.id”
          v-memo=“[item.id <code>=</code> selected]”&gt;
          &lt;p&gt;ID: {{ item.id }} - selected: {{ item.id
          <code>=</code> selected }}&lt;/p&gt; &lt;p&gt;…more child
          nodes&lt;/p&gt; &lt;/div&gt;</p>
          <p>When the component’s selected state changes, a large
          amount of VNodes will be created even though most of the
          items remained exactly the same. The v-memo usage here is
          essentially saying “only update this item if it went from
          non-selected to selected, or the other way around”. This
          allows every unaffected item to reuse its previous VNode
          and skip diffing entirely. Note we don’t need to include
          item.id in the memo dependency array here since Vue
          automatically infers it from the item’s :key.</p>
          <p>WARNING</p>
          <p>When using v-memo with v-for, make sure they are used
          on the same element. v-memo does not work inside
          v-for.</p>
          <p>v-memo can also be used on components to manually
          prevent unwanted updates in certain edge cases where the
          child component update check has been de-optimized. But
          again, it is the developer’s responsibility to specify
          correct dependency arrays to avoid skipping necessary
          updates.</p>
          <p>See also:</p>
          <p><a href=
          "https://vuejs.org/api/built-in-directives.html#v-once">v-once</a></p>
        </div>
      </div>
    </div>
  </div>
  <div id="postamble" class="status">
    <p class="author">Author: Zhicheng Lee</p>
    <p class="date">Created: 2022-03-12 Sat 20:18</p>
  </div>
</body>
</html>
